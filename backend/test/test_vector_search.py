"""
ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
ë²¡í„° ê²€ìƒ‰ ì„œë¹„ìŠ¤ì™€ APIì˜ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""
import sys
import os
from pathlib import Path

# í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì • (ëª¨ë“ˆ import ì „ì— ì„¤ì •)
os.environ["TESTING"] = "true"

# backend ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

import asyncio
import logging
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from core.database import AsyncSessionLocal
from services.vector_search import VectorSearchService
from models.document_chunk import DocumentChunk

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def test_vector_search():
    """ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    async with AsyncSessionLocal() as session:
        try:
            logger.info("=" * 80)
            logger.info("ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘")
            logger.info("=" * 80)
            
            # 1. ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
            search_service = VectorSearchService()
            
            # 2. ì €ì¥ëœ ì²­í¬ ìˆ˜ í™•ì¸
            result = await session.execute(select(DocumentChunk))
            chunks = result.scalars().all()
            chunk_count = len(chunks)
            
            logger.info(f"\nâœ… ì €ì¥ëœ ì²­í¬ ìˆ˜: {chunk_count}ê°œ")
            
            if chunk_count == 0:
                logger.warning("âš ï¸  ê²€ìƒ‰í•  ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤. PDFë¥¼ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
                return
            
            # 3. ìƒ˜í”Œ ì²­í¬ í™•ì¸
            sample_chunk = chunks[0]
            # ì„¸ì…˜ì´ ë‹«íˆê¸° ì „ì— í•„ìš”í•œ ê°’ì„ ë¯¸ë¦¬ ê°€ì ¸ì˜´
            sample_chunk_id = sample_chunk.id
            sample_chunk_content = sample_chunk.content
            
            logger.info(f"\nğŸ“„ ìƒ˜í”Œ ì²­í¬ ì •ë³´:")
            logger.info(f"  - ID: {sample_chunk.id}")
            logger.info(f"  - ë¬¸ì„œ ID: {sample_chunk.document_id}")
            logger.info(f"  - íƒ€ì…: {sample_chunk.chunk_type}")
            logger.info(f"  - ë‚´ìš© (ì• 100ì): {sample_chunk.content[:100]}...")
            logger.info(f"  - í˜ì´ì§€: {sample_chunk.page_number}")
            logger.info(f"  - ì¡°í•­ ë²ˆí˜¸: {sample_chunk.clause_number}")
            
            # 4. í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ëª©ë¡
            test_queries = [
                "ê³¨ì ˆ ì‹œ ë³´ì¥ ì—¬ë¶€ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                "ë³´í—˜ë£Œ ë‚©ì… ë°©ë²•ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
                "ê³„ì•½ í•´ì§€ ì‹œ í™˜ê¸‰ê¸ˆì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                "ë³´í—˜ê¸ˆ ì²­êµ¬ ì ˆì°¨ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"
            ]
            
            # 5. ê° ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
            for i, query in enumerate(test_queries, 1):
                logger.info("\n" + "=" * 80)
                logger.info(f"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ {i}/{len(test_queries)}: {query}")
                logger.info("=" * 80)
                
                # ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
                results = await search_service.search(
                    session=session,
                    query=query,
                    threshold=0.7,
                    limit=5
                )
                
                if results:
                    logger.info(f"\nâœ… ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
                    for j, result in enumerate(results, 1):
                        logger.info(f"\n--- ê²°ê³¼ {j} ---")
                        logger.info(f"ìœ ì‚¬ë„: {result.similarity:.3f}")
                        logger.info(f"ë¬¸ì„œ: {result.document_filename}")
                        logger.info(f"í˜ì´ì§€: {result.page_number}")
                        logger.info(f"ì¡°í•­: {result.clause_number or 'N/A'}")
                        logger.info(f"íƒ€ì…: {result.chunk_type}")
                        logger.info(f"ë‚´ìš© (ì• 200ì):")
                        logger.info(f"{result.content[:200]}...")
                else:
                    logger.warning(f"âš ï¸  '{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # API ì‘ë‹µ ì‹œê°„ì„ ê³ ë ¤í•˜ì—¬ ì ì‹œ ëŒ€ê¸°
                await asyncio.sleep(1)
            
            # 6. ìœ ì‚¬ ì²­í¬ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
            logger.info("\n" + "=" * 80)
            logger.info("ìœ ì‚¬ ì²­í¬ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
            logger.info("=" * 80)
            
            logger.info(f"\nê¸°ì¤€ ì²­í¬ ID: {sample_chunk_id}")
            logger.info(f"ê¸°ì¤€ ì²­í¬ ë‚´ìš© (ì• 100ì): {sample_chunk_content[:100]}...")
            
            similar_chunks = await search_service.get_similar_chunks(
                session=session,
                chunk_id=sample_chunk_id,
                limit=3
            )
            
            if similar_chunks:
                logger.info(f"\nâœ… ìœ ì‚¬ ì²­í¬: {len(similar_chunks)}ê°œ")
                for j, result in enumerate(similar_chunks, 1):
                    logger.info(f"\n--- ìœ ì‚¬ ì²­í¬ {j} ---")
                    logger.info(f"ì²­í¬ ID: {result.chunk_id}")
                    logger.info(f"ìœ ì‚¬ë„: {result.similarity:.3f}")
                    logger.info(f"ë¬¸ì„œ: {result.document_filename}")
                    logger.info(f"ë‚´ìš© (ì• 100ì):")
                    logger.info(f"{result.content[:100]}...")
            else:
                logger.warning("âš ï¸  ìœ ì‚¬í•œ ì²­í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            logger.info("\n" + "=" * 80)
            logger.info("âœ… ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            logger.info("=" * 80)
        
        except Exception as e:
            logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        
        finally:
            await session.close()


async def test_search_with_filters():
    """í•„í„°ë§ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    async with AsyncSessionLocal() as session:
        try:
            logger.info("\n" + "=" * 80)
            logger.info("í•„í„°ë§ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
            logger.info("=" * 80)
            
            search_service = VectorSearchService()
            
            # ë¬¸ì„œ íƒ€ì…ë³„ ê²€ìƒ‰
            query = "ë³´í—˜ê¸ˆ ì²­êµ¬"
            document_types = ["policy", "clause", "faq"]
            
            for doc_type in document_types:
                logger.info(f"\n--- ë¬¸ì„œ íƒ€ì…: {doc_type} ---")
                results = await search_service.search(
                    session=session,
                    query=query,
                    document_type=doc_type,
                    threshold=0.7,
                    limit=3
                )
                logger.info(f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
            
            logger.info("\nâœ… í•„í„°ë§ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
        except Exception as e:
            logger.error(f"âŒ í•„í„°ë§ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        finally:
            await session.close()


if __name__ == "__main__":
    # ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    asyncio.run(test_vector_search())
    
    # í•„í„°ë§ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    # asyncio.run(test_search_with_filters())


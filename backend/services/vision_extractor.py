"""
GPT-4 Visionì„ ì‚¬ìš©í•œ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„œë¹„ìŠ¤
"""
import asyncio
import base64
import io
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from io import BytesIO

import fitz  # PyMuPDF for PDF to image conversion
from PIL import Image
from openai import AsyncOpenAI
import tenacity

from pdf2image import convert_from_path

from core.config import settings
from core.poppler_config import POPPLER_PATH
from services.image_preprocessor import ImagePreprocessor

logger = logging.getLogger(__name__)


class VisionExtractor:
    """GPT-4 Vision APIë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        self.preprocessor = ImagePreprocessor()
        self.model = "gpt-4o"  # GPT-4 with vision
        self.dpi = 300
        self.max_retries = 3
    
    async def pdf_to_images(
        self,
        pdf_path: str,
        dpi: int = 300,
        document_id: Optional[int] = None,
        save_images: bool = True
    ) -> List[Image.Image]:
        """
        PDF íŒŒì¼ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            dpi: ì´ë¯¸ì§€ í•´ìƒë„ (Dots Per Inch)
            document_id: ë¬¸ì„œ ID (ì´ë¯¸ì§€ ì €ì¥ ì‹œ í•„ìš”)
            save_images: ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥ ì—¬ë¶€
            
        Returns:
            PIL Image ë¦¬ìŠ¤íŠ¸
        """
        dpi = dpi or self.dpi
        logger.info(f"PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ ì‹œì‘: {pdf_path} (DPI={dpi})")
        
        try:
            images = convert_from_path(
                pdf_path,
                dpi=dpi,
                fmt='png',
                poppler_path=POPPLER_PATH  # Windows Poppler ê²½ë¡œ ì§€ì›
            )
            logger.info(f"ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ: {len(images)}í˜ì´ì§€")
            
            # ì´ë¯¸ì§€ ì €ì¥ (ì˜µì…˜)
            if save_images and document_id is not None:
                await self._save_images(images, document_id)
            
            return images
        
        except Exception as e:
            logger.error(f"PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            if "poppler" in str(e).lower():
                logger.error(
                    "Popplerê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                    "Windows: https://github.com/oschwartz10612/poppler-windows/releases ì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ "
                    "í™˜ê²½ ë³€ìˆ˜ POPPLER_PATHë¥¼ ì„¤ì •í•˜ì„¸ìš”."
                )
            raise
    
    async def _save_images(
        self,
        images: List[Image.Image],
        document_id: int
    ) -> List[str]:
        """
        ë³€í™˜ëœ ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            images: PIL Image ë¦¬ìŠ¤íŠ¸
            document_id: ë¬¸ì„œ ID
            
        Returns:
            ì €ì¥ëœ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        from pathlib import Path
        
        # ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        image_dir = Path("uploads/images") / str(document_id)
        image_dir.mkdir(parents=True, exist_ok=True)
        
        saved_paths = []
        
        logger.info(f"ì´ë¯¸ì§€ ì €ì¥ ì‹œì‘: {len(images)}í˜ì´ì§€ â†’ {image_dir}")
        
        for page_num, image in enumerate(images, start=1):
            try:
                # íŒŒì¼ëª…: page_1.png, page_2.png, ...
                filename = f"page_{page_num}.png"
                file_path = image_dir / filename
                
                # PNGë¡œ ì €ì¥
                image.save(file_path, "PNG")
                saved_paths.append(str(file_path))
                
                # 100í˜ì´ì§€ë§ˆë‹¤ ë¡œê·¸
                if page_num % 100 == 0:
                    logger.info(f"ì´ë¯¸ì§€ ì €ì¥ ì§„í–‰: {page_num}/{len(images)}í˜ì´ì§€")
            
            except Exception as e:
                logger.error(f"í˜ì´ì§€ {page_num} ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        logger.info(f"ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {len(saved_paths)}ê°œ íŒŒì¼")
        return saved_paths
    
    def preprocess_image(
        self,
        image: Image.Image,
        apply_preprocessing: bool = True
    ) -> Image.Image:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        
        Args:
            image: PIL Image
            apply_preprocessing: ì „ì²˜ë¦¬ ì ìš© ì—¬ë¶€
            
        Returns:
            ì „ì²˜ë¦¬ëœ PIL Image
        """
        if not apply_preprocessing:
            return image
        
        # numpy arrayë¡œ ë³€í™˜ í›„ ì „ì²˜ë¦¬
        np_image = self.preprocessor.pil_to_numpy(image)
        
        # ì „ì²˜ë¦¬ ì ìš©
        processed = self.preprocessor.preprocess(
            np_image,
            apply_grayscale=False,  # ì»¬ëŸ¬ ìœ ì§€ (Vision API ìµœì í™”)
            apply_noise_removal=True,
            apply_deskew=False  # ì„±ëŠ¥ ê³ ë ¤í•˜ì—¬ ê¸°ë³¸ ë¹„í™œì„±í™”
        )
        
        # PIL Imageë¡œ ë³€í™˜
        return self.preprocessor.numpy_to_pil(processed)
    
    def image_to_base64(self, image: Image.Image) -> str:
        """
        PIL Imageë¥¼ base64 ë¬¸ìì—´ë¡œ ë³€í™˜
        
        Args:
            image: PIL Image
            
        Returns:
            base64 ì¸ì½”ë”©ëœ ë¬¸ìì—´
        """
        buffer = BytesIO()
        image.save(buffer, format='PNG')
        img_bytes = buffer.getvalue()
        return base64.b64encode(img_bytes).decode('utf-8')
    
    @tenacity.retry(
        stop=tenacity.stop_after_attempt(3),
        wait=tenacity.wait_exponential(multiplier=1, min=2, max=10),
        retry=tenacity.retry_if_exception_type(Exception),
        before_sleep=lambda retry_state: logger.warning(
            f"ì¬ì‹œë„ {retry_state.attempt_number}/3"
        )
    )
    async def extract_text_from_image(
        self,
        image: Image.Image,
        page_number: int,
        context_text: Optional[str] = None
    ) -> Dict:
        """
        GPT-4 Visionìœ¼ë¡œ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        
        Args:
            image: PIL Image
            page_number: í˜ì´ì§€ ë²ˆí˜¸
            context_text: PyMuPDFì—ì„œ ì¶”ì¶œí•œ ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸ (í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ)
            
        Returns:
            ì¶”ì¶œ ê²°ê³¼
        """
        logger.info(f"í˜ì´ì§€ {page_number} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘ (context={'ìˆìŒ' if context_text else 'ì—†ìŒ'})")
        
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        img_base64 = self.image_to_base64(image)
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„± (í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ vs ì¼ë°˜ ëª¨ë“œ)
        if context_text:
            # í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ: í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ í™œìš©
            prompt_text = f"""ë‹¤ìŒì€ ì´ í˜ì´ì§€ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤:

---
{context_text}
---

ìœ„ í…ìŠ¤íŠ¸ë¥¼ **ì°¸ê³ í•˜ì—¬**, ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ê²€ì¦í•˜ê³  ë³´ì™„í•´ì£¼ì„¸ìš”.

**ì‘ì—… ì§€ì¹¨:**
1. **í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì¶œ (ìµœìš°ì„ ):**
   - í˜ì´ì§€ ìƒë‹¨/í•˜ë‹¨ì— ì¸ì‡„ëœ í˜ì´ì§€ ë²ˆí˜¸ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë§¨ ì•ì— í‘œì‹œ:
     ### [í˜ì´ì§€ë²ˆí˜¸]
   - ì˜ˆì‹œ: ### 3
   - í˜ì´ì§€ ë²ˆí˜¸ê°€ ì—†ìœ¼ë©´ ìƒëµí•˜ì„¸ìš”
2. í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ì •í™•í•œì§€ ì´ë¯¸ì§€ë¡œ í™•ì¸
3. **í‘œ êµ¬ì¡°ì™€ ë°ì´í„°**ë¥¼ ì´ë¯¸ì§€ ê¸°ë°˜ìœ¼ë¡œ ì •í™•íˆ ê²€ì¦ ë° ë³´ì™„
4. **ì´ë¯¸ì§€/ë„ì‹/ê·¸ë¦¼**ì´ ìˆë‹¤ë©´ ìƒì„¸íˆ ì„¤ëª…:
   - ì´ë¯¸ì§€ ë‚´ ëª¨ë“  í…ìŠ¤íŠ¸, ë¼ë²¨, ë²ˆí˜¸ ì¶”ì¶œ
   - ë„ì‹ì˜ êµ¬ì¡°ì™€ ìš”ì†Œ ê°„ ê´€ê³„ (í™”ì‚´í‘œ, ì—°ê²°ì„  ë“±)
   - í•´ë¶€í•™ì  ë„ì‹ì¸ ê²½ìš° ê° ë¶€ìœ„ì˜ ëª…ì¹­ê³¼ ìœ„ì¹˜
   - ì´ë¯¸ì§€ê°€ ë¬¸ì„œ ë‚´ìš©ê³¼ì˜ ê´€ê³„
   - í˜•ì‹: [ì´ë¯¸ì§€ ìƒì„¸ ì„¤ëª…:\\në‚´ìš©...\\n]
5. ë ˆì´ì•„ì›ƒ ì •ë³´ (ë“¤ì—¬ì“°ê¸°, ëª©ë¡ êµ¬ì¡° ë“±) ë³´ì™„
6. íŠ¹ìˆ˜ ë¬¸ìë‚˜ ê¸°í˜¸ê°€ ëˆ„ë½ë˜ì—ˆë‹¤ë©´ ì¶”ê°€

**ì¶œë ¥ í˜•ì‹:**
- Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±
- í˜ì´ì§€ ë²ˆí˜¸ê°€ ìˆë‹¤ë©´ ë§¨ ì•ì— ### í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
- ì¡°í•­ ë²ˆí˜¸, ì œëª©, ë‚´ìš©ì„ ëª…í™•íˆ êµ¬ë¶„
- í‘œëŠ” Markdown í‘œ í˜•ì‹ (|)ìœ¼ë¡œ ì‘ì„±"""
        else:
            # ì¼ë°˜ ëª¨ë“œ: ì´ë¯¸ì§€ë§Œìœ¼ë¡œ ì¶”ì¶œ
            prompt_text = """ì´ ë³´í—˜ ì•½ê´€ í˜ì´ì§€ì˜ ëª¨ë“  ë‚´ìš©ì„ Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”:
1. **í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì¶œ (ìµœìš°ì„ ):**
   - í˜ì´ì§€ ìƒë‹¨/í•˜ë‹¨ì— ì¸ì‡„ëœ í˜ì´ì§€ ë²ˆí˜¸ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë§¨ ì•ì— í‘œì‹œ:
     ### [í˜ì´ì§€ë²ˆí˜¸]
   - ì˜ˆì‹œ: ### 3
   - í˜ì´ì§€ ë²ˆí˜¸ê°€ ì—†ìœ¼ë©´ ìƒëµí•˜ì„¸ìš”
2. ëª¨ë“  í…ìŠ¤íŠ¸ (ì œëª©, ë³¸ë¬¸, ê°ì£¼ ë“±)
3. í‘œëŠ” Markdown í‘œ í˜•ì‹ (|)ìœ¼ë¡œ ë³€í™˜
4. **ì´ë¯¸ì§€ëŠ” ë°˜ë“œì‹œ ìƒì„¸íˆ ì„¤ëª…**:
   - ì´ë¯¸ì§€ ë‚´ ëª¨ë“  í…ìŠ¤íŠ¸, ë¼ë²¨, ë²ˆí˜¸ë¥¼ ì¶”ì¶œ
   - ë„ì‹ì˜ êµ¬ì¡°ì™€ ìš”ì†Œ ê°„ ê´€ê³„ ì„¤ëª… (ì˜ˆ: í™”ì‚´í‘œ, ì—°ê²°ì„ )
   - í•´ë¶€í•™ì  ë„ì‹ì¸ ê²½ìš° ê° ë¶€ìœ„ì˜ ëª…ì¹­ê³¼ ìœ„ì¹˜ ì„¤ëª…
   - ì´ë¯¸ì§€ê°€ ë¬¸ì„œì—ì„œ ì„¤ëª…í•˜ëŠ” ë‚´ìš©ê³¼ì˜ ê´€ê³„
   - í˜•ì‹: [ì´ë¯¸ì§€ ìƒì„¸ ì„¤ëª…:\në‚´ìš©...\n]
5. í˜ì´ì§€ ë ˆì´ì•„ì›ƒê³¼ êµ¬ì¡°ë¥¼ ìµœëŒ€í•œ ìœ ì§€

**ì¤‘ìš”: í˜ì´ì§€ì— ì¸ì‡„ëœ í˜ì´ì§€ ë²ˆí˜¸ê°€ ìˆë‹¤ë©´ ì¶œë ¥ì˜ ë§¨ ì•ì— ### [í˜ì´ì§€ë²ˆí˜¸] í˜•ì‹ìœ¼ë¡œ ë°˜ë“œì‹œ í‘œì‹œí•˜ì„¸ìš”!**

ì¡°í•­ ë²ˆí˜¸, ì œëª©, ë‚´ìš©ì„ ì •í™•íˆ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”."""
        
        # GPT-4 Vision API í˜¸ì¶œ
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ë³´í—˜ ì•½ê´€ ë¬¸ì„œë¥¼ ì •í™•í•˜ê²Œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í‘œ, ì´ë¯¸ì§€, ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ë¹ ì§ì—†ì´ Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt_text
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{img_base64}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=8192,  # ì´ë¯¸ì§€ ìƒì„¸ ì„¤ëª…ì„ ìœ„í•´ ì¦ê°€
                temperature=0.1  # ì •í™•ì„±ì„ ìœ„í•´ ë‚®ì€ temperature
            )
            
            extracted_text = response.choices[0].message.content
            
            # Markdown ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±° (```markdown ... ``` í˜•íƒœ)
            if extracted_text:
                # ì•ë’¤ ê³µë°± ì œê±°
                extracted_text = extracted_text.strip()
                
                # ```markdown ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
                if extracted_text.startswith('```markdown'):
                    extracted_text = extracted_text[len('```markdown'):].lstrip('\n')
                # ``` ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
                elif extracted_text.startswith('```'):
                    extracted_text = extracted_text[3:].lstrip('\n')
                
                # ``` ìœ¼ë¡œ ëë‚˜ëŠ” ê²½ìš°
                if extracted_text.endswith('```'):
                    extracted_text = extracted_text[:-3].rstrip('\n')
                
                # ìµœì¢… ê³µë°± ì •ë¦¬
                extracted_text = extracted_text.strip()
            
            result = {
                'page_number': page_number,
                'content': extracted_text,
                'model': self.model,
                'has_context': context_text is not None,
                'tokens_used': {
                    'prompt': response.usage.prompt_tokens,
                    'completion': response.usage.completion_tokens,
                    'total': response.usage.total_tokens
                }
            }
            
            logger.info(
                f"í˜ì´ì§€ {page_number} ì¶”ì¶œ ì™„ë£Œ: "
                f"{len(extracted_text)} ë¬¸ì, "
                f"{response.usage.total_tokens} í† í°"
            )
            return result
        
        except Exception as e:
            logger.error(f"í˜ì´ì§€ {page_number} ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    async def extract_batch(
        self,
        images: List[Image.Image],
        start_page: int = 1,
        context_texts: Optional[List[str]] = None
    ) -> List[Dict]:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬
        
        Args:
            images: PIL Image ë¦¬ìŠ¤íŠ¸
            start_page: ì‹œì‘ í˜ì´ì§€ ë²ˆí˜¸
            context_texts: í˜ì´ì§€ë³„ ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ (í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ)
            
        Returns:
            ì¶”ì¶œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        logger.info(
            f"ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(images)}í˜ì´ì§€ "
            f"(context={'ìˆìŒ' if context_texts else 'ì—†ìŒ'})"
        )
        
        # Semaphoreë¡œ ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ (OpenAI API rate limit ê³ ë ¤)
        semaphore = asyncio.Semaphore(50)  # ìµœëŒ€ 50ê°œ ë™ì‹œ ìš”ì²­ (3 â†’ 50 ìµœì í™”)
        
        async def process_with_semaphore(
            image: Image.Image, 
            page_num: int, 
            context: Optional[str] = None
        ):
            async with semaphore:
                return await self.extract_text_from_image(image, page_num, context)
        
        # ëª¨ë“  í˜ì´ì§€ë¥¼ ë³‘ë ¬ ì²˜ë¦¬
        tasks = []
        for idx, img in enumerate(images):
            page_num = start_page + idx
            context = None
            if context_texts and idx < len(context_texts):
                context = context_texts[idx]
            tasks.append(process_with_semaphore(img, page_num, context))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ì„±ê³µí•œ ê²°ê³¼ë§Œ í•„í„°ë§
        successful_results = []
        for idx, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"í˜ì´ì§€ {start_page + idx} ì²˜ë¦¬ ì‹¤íŒ¨: {result}")
            else:
                successful_results.append(result)
        
        logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(successful_results)}/{len(images)} ì„±ê³µ")
        return successful_results
    
    async def extract_full_document(
        self,
        pdf_path: str,
        apply_preprocessing: bool = True,
        max_concurrent: int = 3,
        document_id: Optional[int] = None,
        save_images: bool = True
    ) -> Dict:
        """
        PDF ì „ì²´ ë¬¸ì„œ ì¶”ì¶œ (ë©”ì¸ í•¨ìˆ˜)
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            apply_preprocessing: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì ìš© ì—¬ë¶€
            max_concurrent: ìµœëŒ€ ë™ì‹œ ì²˜ë¦¬ ìˆ˜
            document_id: ë¬¸ì„œ ID (ì´ë¯¸ì§€ ì €ì¥ ì‹œ í•„ìš”)
            save_images: ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥ ì—¬ë¶€
            
        Returns:
            ì¶”ì¶œ ê²°ê³¼
        """
        from datetime import datetime
        start_time = datetime.now()
        
        logger.info(f"GPT-4 Vision ì¶”ì¶œ ì‹œì‘: {pdf_path}")
        
        # 1. PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ë° ì €ì¥)
        images = await self.pdf_to_images(
            pdf_path,
            document_id=document_id,
            save_images=save_images
        )
        
        # 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì˜µì…˜)
        if apply_preprocessing:
            logger.info("ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì ìš©")
            images = [self.preprocess_image(img) for img in images]
        
        # 3. ë°°ì¹˜ ì²˜ë¦¬
        results = await self.extract_batch(images)
        
        # 4. ê²°ê³¼ ë³‘í•©
        pages = []
        total_tokens = 0
        
        for result in sorted(results, key=lambda x: x['page_number']):
            pages.append({
                'page_number': result['page_number'],
                'content': result['content']
            })
            total_tokens += result['tokens_used']['total']
        
        # Markdownìœ¼ë¡œ ë³‘í•©
        markdown_parts = []
        for page in pages:
            markdown_parts.append(f"## í˜ì´ì§€ {page['page_number']}\n")
            markdown_parts.append(page['content'])
            markdown_parts.append("\n---\n")
        
        full_markdown = "\n".join(markdown_parts)
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        logger.info(
            f"GPT-4 Vision ì¶”ì¶œ ì™„ë£Œ: {len(pages)}í˜ì´ì§€, "
            f"{total_tokens} í† í°, {processing_time:.2f}ì´ˆ"
        )
        
        return {
            'markdown': full_markdown,
            'pages': pages,
            'metadata': {
                'processing_time': processing_time,
                'total_pages': len(pages),
                'total_chars': len(full_markdown),
                'total_tokens': total_tokens,
                'model': self.model,
                'dpi': self.dpi,
            }
        }
    
    async def extract_with_context(
        self,
        pdf_path: str,
        context_texts: List[str],
        apply_preprocessing: bool = True,
        document_id: Optional[int] = None,
        save_images: bool = True
    ) -> Dict:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹: PyMuPDF í…ìŠ¤íŠ¸ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©í•œ Vision ì¶”ì¶œ
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            context_texts: í˜ì´ì§€ë³„ PyMuPDF ì¶”ì¶œ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            apply_preprocessing: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì ìš© ì—¬ë¶€
            document_id: ë¬¸ì„œ ID (ì´ë¯¸ì§€ ì €ì¥ ì‹œ í•„ìš”)
            save_images: ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥ ì—¬ë¶€
            
        Returns:
            ì¶”ì¶œ ê²°ê³¼
        """
        from datetime import datetime
        start_time = datetime.now()
        
        logger.info(
            f"ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ Vision ì¶”ì¶œ ì‹œì‘: {pdf_path} "
            f"(ì»¨í…ìŠ¤íŠ¸: {len(context_texts)}í˜ì´ì§€)"
        )
        
        # 1. PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ë° ì €ì¥)
        images = await self.pdf_to_images(
            pdf_path,
            document_id=document_id,
            save_images=save_images
        )
        
        # í˜ì´ì§€ ìˆ˜ ê²€ì¦
        if len(images) != len(context_texts):
            logger.warning(
                f"í˜ì´ì§€ ìˆ˜ ë¶ˆì¼ì¹˜: ì´ë¯¸ì§€={len(images)}, "
                f"ì»¨í…ìŠ¤íŠ¸={len(context_texts)}"
            )
        
        # 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì˜µì…˜)
        if apply_preprocessing:
            logger.info("ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì ìš©")
            images = [self.preprocess_image(img) for img in images]
        
        # 3. í•˜ì´ë¸Œë¦¬ë“œ ë°°ì¹˜ ì²˜ë¦¬ (ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸ í™œìš©)
        results = await self.extract_batch(
            images, 
            start_page=1,
            context_texts=context_texts
        )
        
        # 4. ê²°ê³¼ ë³‘í•©
        pages = []
        total_tokens = 0
        
        for result in sorted(results, key=lambda x: x['page_number']):
            pages.append({
                'page_number': result['page_number'],
                'content': result['content'],
                'has_context': result.get('has_context', False)
            })
            total_tokens += result['tokens_used']['total']
        
        # Markdownìœ¼ë¡œ ë³‘í•©
        markdown_parts = []
        for page in pages:
            markdown_parts.append(f"## í˜ì´ì§€ {page['page_number']}\n")
            markdown_parts.append(page['content'])
            markdown_parts.append("\n---\n")
        
        full_markdown = "\n".join(markdown_parts)
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        logger.info(
            f"âœ… í•˜ì´ë¸Œë¦¬ë“œ Vision ì¶”ì¶œ ì™„ë£Œ: {len(pages)}í˜ì´ì§€, "
            f"{total_tokens} í† í°, {processing_time:.2f}ì´ˆ"
        )
        
        return {
            'markdown': full_markdown,
            'pages': pages,
            'metadata': {
                'processing_time': processing_time,
                'total_pages': len(pages),
                'total_chars': len(full_markdown),
                'total_tokens': total_tokens,
                'model': self.model,
                'dpi': self.dpi,
                'hybrid_mode': True,
                'context_pages': len(context_texts)
            }
        }


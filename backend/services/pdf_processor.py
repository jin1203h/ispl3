"""
PDF ì „ì²˜ë¦¬ ì„œë¹„ìŠ¤
Path 1(PyMuPDF4LLM) + Path 2(GPT-4 Vision) í†µí•©

ì²˜ë¦¬ ë°©ì‹:
- pymupdf: PyMuPDF4LLMìœ¼ë¡œ ë¹ ë¥¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
- vision: GPT-4 Visionìœ¼ë¡œ ì´ë¯¸ì§€ ê¸°ë°˜ ì¶”ì¶œ
- both: í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ - PyMuPDF í…ìŠ¤íŠ¸ë¥¼ Vision APIì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©
  * PyMuPDFë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë¹ ë¥´ê³  ì •í™•)
  * Vision APIì— í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ì œê³µ
  * Visionì´ í…ìŠ¤íŠ¸ë¥¼ ê²€ì¦í•˜ê³  í‘œ/ì´ë¯¸ì§€/ë ˆì´ì•„ì›ƒ ì •ë³´ë¥¼ ë³´ì™„
"""
from pathlib import Path
from typing import Dict, Optional, Literal, List
import logging
from datetime import datetime
import asyncio

from services.pymupdf_extractor import PyMuPDFExtractor
from services.vision_extractor import VisionExtractor
from services.hybrid_merger import HybridMerger
from services.chunker import TextChunker
from services.embedding_service import EmbeddingService

logger = logging.getLogger(__name__)


class PDFProcessor:
    """PDF ì²˜ë¦¬ ë©”ì¸ ì„œë¹„ìŠ¤"""
    
    def __init__(self, embedding_service=None, text_chunker=None):
        """
        ì´ˆê¸°í™”
        
        Args:
            embedding_service: EmbeddingService ì¸ìŠ¤í„´ìŠ¤ (ì˜ì¡´ì„± ì£¼ì…)
            text_chunker: TextChunker ì¸ìŠ¤í„´ìŠ¤ (ì˜ì¡´ì„± ì£¼ì…)
        """
        self.pymupdf_extractor = PyMuPDFExtractor()
        self.vision_extractor = VisionExtractor()
        self.hybrid_merger = HybridMerger()
        
        # ì˜ì¡´ì„± ì£¼ì…: ì™¸ë¶€ì—ì„œ ì£¼ì…ë˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ìƒì„± (í•˜ìœ„ í˜¸í™˜ì„±)
        if text_chunker is None:
            from services.chunker import TextChunker
            text_chunker = TextChunker(chunk_size=1000, overlap=100)
            logger.warning("PDFProcessor: text_chunkerê°€ ì£¼ì…ë˜ì§€ ì•Šì•„ ê¸°ë³¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±")
        
        if embedding_service is None:
            from services.embedding_service import EmbeddingService
            embedding_service = EmbeddingService()
            logger.warning("PDFProcessor: embedding_serviceê°€ ì£¼ì…ë˜ì§€ ì•Šì•„ ê¸°ë³¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±")
        
        self.chunker = text_chunker
        self.embedding_service = embedding_service
        logger.info("PDFProcessor ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def process_pdf(
        self,
        pdf_path: str,
        document_id: int,
        save_markdown: bool = True,
        method: Literal["pymupdf", "vision", "both"] = "pymupdf",
        enable_chunking: bool = False,
        db_session = None  # AsyncSession (optional)
    ) -> Dict:
        """
        PDF íŒŒì¼ ì²˜ë¦¬
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            document_id: ë¬¸ì„œ ID
            save_markdown: Markdown íŒŒì¼ ì €ì¥ ì—¬ë¶€
            method: ì²˜ë¦¬ ë°©ë²• ("pymupdf", "vision", "both")
            enable_chunking: ì²­í‚¹ ë° ì„ë² ë”© í™œì„±í™” ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        start_time = datetime.now()
        logger.info(
            f"PDF ì²˜ë¦¬ ì‹œì‘: {pdf_path} "
            f"(document_id={document_id}, method={method})"
        )
        
        try:
            if method == "pymupdf":
                result = self._process_with_pymupdf(pdf_path, document_id)
            elif method == "vision":
                result = await self._process_with_vision_async(pdf_path, document_id)
            elif method == "both":
                result = await self._process_with_both_async(pdf_path, document_id)
            else:
                raise ValueError(f"Unknown method: {method}")
            
            # Markdown íŒŒì¼ ì €ì¥
            if save_markdown:
                markdown_path = self._save_markdown(
                    result['markdown'],
                    pdf_path,
                    document_id,
                    method
                )
                result['markdown_path'] = str(markdown_path)
            
            # ì²­í‚¹ ë° ì„ë² ë”©
            if enable_chunking:
                logger.info(f"ì²­í‚¹ ì‹œì‘: enable_chunking={enable_chunking}, session={'ìˆìŒ' if db_session else 'ì—†ìŒ'}")
                pages_info = result.get('pages', [])  # Visionì˜ pages ì •ë³´
                chunks_data = await self._chunk_and_embed(
                    result['markdown'],
                    document_id,
                    db_session,
                    pages_info=pages_info
                )
                result['chunks'] = chunks_data
                logger.info(f"ì²­í‚¹ ì™„ë£Œ: {chunks_data.get('total_chunks', 0)}ê°œ ì²­í¬")
            else:
                logger.warning("ì²­í‚¹ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = (datetime.now() - start_time).total_seconds()
            result['processing_time_seconds'] = processing_time
            result['method'] = method
            
            logger.info(f"PDF ì²˜ë¦¬ ì™„ë£Œ ({method}): {processing_time:.2f}ì´ˆ")
            return {
                'status': 'success',
                'data': result,
                'processing_time_ms': int(processing_time * 1000)
            }
            
        except Exception as e:
            processing_time = (datetime.now() - start_time).total_seconds()
            logger.error(f"PDF ì²˜ë¦¬ ì‹¤íŒ¨ ({method}): {e}")
            return {
                'status': 'failed',
                'error': str(e),
                'processing_time_ms': int(processing_time * 1000),
                'method': method
            }
    
    def _process_with_pymupdf(self, pdf_path: str, document_id: int) -> Dict:
        """PyMuPDF4LLMìœ¼ë¡œ ì²˜ë¦¬ (Path 1)"""
        logger.info("Path 1: PyMuPDF4LLM ì²˜ë¦¬")
        return self.pymupdf_extractor.extract_full_document(
            pdf_path,
            document_id=document_id,
            save_images=True
        )
    
    async def _process_with_vision_async(self, pdf_path: str, document_id: int = None) -> Dict:
        """GPT-4 Visionìœ¼ë¡œ ì²˜ë¦¬ (Path 2) - async ë²„ì „"""
        logger.info("Path 2: GPT-4 Vision ì²˜ë¦¬")
        return await self.vision_extractor.extract_full_document(
            pdf_path,
            document_id=document_id,
            save_images=True
        )
    
    async def _process_with_both_async(self, pdf_path: str, document_id: int) -> Dict:
        """
        ì§„ì •í•œ í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬: PyMuPDF í…ìŠ¤íŠ¸ + Vision API (í…ìŠ¤íŠ¸ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©)
        
        ë³€ê²½ ì‚¬í•­:
        - ê¸°ì¡´: PyMuPDFì™€ Visionì„ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ í›„ ë³‘í•©
        - ì‹ ê·œ: PyMuPDF í…ìŠ¤íŠ¸ë¥¼ Vision APIì˜ inputìœ¼ë¡œ ì œê³µí•˜ì—¬ ë³´ì™„
        """
        logger.info("ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬: PyMuPDF í…ìŠ¤íŠ¸ + Vision API")
        
        # Step 1: PyMuPDFë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        logger.info("Step 1: PyMuPDF í…ìŠ¤íŠ¸ ì¶”ì¶œ")
        pymupdf_result = self._process_with_pymupdf(pdf_path, document_id)
        
        # Step 2: í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ (Vision APIì— ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ)
        logger.info("Step 2: í˜ì´ì§€ë³„ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„")
        pages_data = pymupdf_result.get('pages', [])
        context_texts = [page['content'] for page in pages_data]
        
        logger.info(f"ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ ì™„ë£Œ: {len(context_texts)}í˜ì´ì§€")
        
        # Step 3: Vision API í˜¸ì¶œ (í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ - í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ í™œìš©)
        logger.info("Step 3: Vision API í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì¶œ")
        vision_result = await self.vision_extractor.extract_with_context(
            pdf_path,
            context_texts=context_texts,
            apply_preprocessing=True,
            document_id=document_id,
            save_images=True
        )
        
        logger.info("Step 4: í•˜ì´ë¸Œë¦¬ë“œ ê²°ê³¼ ìƒì„±")
        
        # Vision ê²°ê³¼ë¥¼ ë©”ì¸ìœ¼ë¡œ ì‚¬ìš© (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ì •ë³´ ëª¨ë‘ í¬í•¨)
        # PyMuPDF ê²°ê³¼ëŠ” ì°¸ê³ ìš©ìœ¼ë¡œ ë³´ê´€
        return {
            'markdown': vision_result['markdown'],
            'pages': vision_result.get('pages', []),  # â† pages ì •ë³´ ì¶”ê°€
            'method': 'hybrid',  # í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹
            'metadata': {
                'total_pages': pymupdf_result['metadata'].get('total_pages', 0),
                'processing_time': (
                    pymupdf_result['metadata'].get('processing_time', 0) +
                    vision_result['metadata'].get('processing_time', 0)
                ),
                'hybrid_mode': True,
                'pymupdf_chars': pymupdf_result['metadata'].get('total_chars', 0),
                'vision_chars': vision_result['metadata'].get('total_chars', 0),
                'vision_tokens': vision_result['metadata'].get('total_tokens', 0),
                'table_count': pymupdf_result['metadata'].get('table_count', 0),
                'image_count': pymupdf_result['metadata'].get('image_count', 0),
            },
            # ë””ë²„ê¹…ìš© ì›ë³¸ ê²°ê³¼ í¬í•¨
            'pymupdf_result': pymupdf_result,
            'vision_result': vision_result
        }
    
    def _save_markdown(
        self,
        markdown_text: str,
        pdf_path: str,
        document_id: int,
        method: str = "pymupdf"
    ) -> Path:
        """
        Markdown íŒŒì¼ ì €ì¥
        
        Args:
            markdown_text: Markdown í…ìŠ¤íŠ¸
            pdf_path: ì›ë³¸ PDF ê²½ë¡œ
            document_id: ë¬¸ì„œ ID
            
        Returns:
            ì €ì¥ëœ Markdown íŒŒì¼ ê²½ë¡œ
        """
        pdf_path = Path(pdf_path)
        original_name = pdf_path.stem  # ì´ë¯¸ document_id í¬í•¨ë¨ (ì˜ˆ: sample_policy_27)
        
        # uploads/documents/ ë””ë ‰í† ë¦¬ì— ì €ì¥
        # method ì ‘ë¯¸ì‚¬ ì¶”ê°€
        method_suffix = f"_{method}" if method != "pymupdf" else ""
        md_filename = f"{original_name}{method_suffix}.md"
        md_path = Path("uploads/documents") / md_filename
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        md_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Markdown ì €ì¥
        md_path.write_text(markdown_text, encoding='utf-8')
        logger.info(f"Markdown ì €ì¥: {md_path}")
        
        return md_path
    
    def validate_pdf(self, pdf_path: str) -> bool:
        """
        PDF íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ìœ íš¨ ì—¬ë¶€
        """
        path = Path(pdf_path)
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not path.exists():
            logger.error(f"PDF íŒŒì¼ ì—†ìŒ: {pdf_path}")
            return False
        
        # í™•ì¥ì í™•ì¸
        if path.suffix.lower() != '.pdf':
            logger.error(f"PDF íŒŒì¼ ì•„ë‹˜: {pdf_path}")
            return False
        
        # íŒŒì¼ í¬ê¸° í™•ì¸ (ìµœì†Œ 1KB)
        if path.stat().st_size < 1024:
            logger.error(f"PDF íŒŒì¼ í¬ê¸° ë„ˆë¬´ ì‘ìŒ: {pdf_path}")
            return False
        
        return True
    
    def _assign_vision_page_numbers(
        self,
        chunks: List,
        markdown_text: str,
        pages_info: List[Dict]
    ) -> List:
        """
        ê° ì²­í¬ì— Visionì˜ page_numberë¥¼ í• ë‹¹í•©ë‹ˆë‹¤.
        
        Args:
            chunks: ì²­í¬ ë¦¬ìŠ¤íŠ¸
            markdown_text: ì „ì²´ Markdown í…ìŠ¤íŠ¸
            pages_info: Visionì˜ í˜ì´ì§€ ì •ë³´
        
        Returns:
            page_numberê°€ í• ë‹¹ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        from services.chunker import Chunk
        
        # ë””ë²„ê¹…: ì…ë ¥ê°’ í™•ì¸
        logger.info(f"=== page_number í• ë‹¹ ì‹œì‘ ===")
        logger.info(f"ì²­í¬ ìˆ˜: {len(chunks)}")
        logger.info(f"pages_info ìˆ˜: {len(pages_info)}")
        logger.info(f"Markdown ê¸¸ì´: {len(markdown_text)}")
        logger.info(f"Markdown ì•ë¶€ë¶„ 200ì:\n{markdown_text[:200]}")
        
        # Markdownì—ì„œ "## í˜ì´ì§€ X" ìœ„ì¹˜ ì°¾ê¸°
        page_positions = []
        for page_info in pages_info:
            vision_page_num = page_info['page_number']  # 1, 2, 3...
            pattern = f"## í˜ì´ì§€ {vision_page_num}"
            pos = markdown_text.find(pattern)
            
            logger.debug(f"íŒ¨í„´ '{pattern}' ê²€ìƒ‰ ê²°ê³¼: pos={pos}")
            
            if pos >= 0:
                page_positions.append({
                    'vision_page_number': vision_page_num,
                    'position': pos
                })
            else:
                logger.warning(f"âš ï¸ íŒ¨í„´ '{pattern}'ì„ Markdownì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        
        # ìœ„ì¹˜ ê¸°ì¤€ ì •ë ¬
        page_positions.sort(key=lambda x: x['position'])
        
        logger.info(f"ê°ì§€ëœ í˜ì´ì§€ ìœ„ì¹˜: {len(page_positions)}ê°œ")
        if page_positions:
            for pp in page_positions[:3]:
                logger.info(f"  - í˜ì´ì§€ {pp['vision_page_number']}: position {pp['position']}")
        
        if not page_positions:
            logger.error("âŒ í˜ì´ì§€ ìœ„ì¹˜ë¥¼ í•˜ë‚˜ë„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!")
            logger.error(f"Markdown ì‹œì‘ 500ì:\n{markdown_text[:500]}")
            return chunks
        
        # ê° ì²­í¬ê°€ ì–´ëŠ Vision í˜ì´ì§€ì— ì†í•˜ëŠ”ì§€ íŒë‹¨
        success_count = 0
        fail_count = 0
        
        for chunk in chunks:
            # ì²­í¬ì˜ ìœ„ì¹˜ ì°¾ê¸° - ì›ë³¸ ê·¸ëŒ€ë¡œ ê²€ìƒ‰ (ì •ê·œí™” ì—†ìŒ)
            search_content = chunk.content[:100] if len(chunk.content) > 100 else chunk.content
            
            # ì›ë³¸ Markdownì—ì„œ ì›ë³¸ ì²­í¬ ê²€ìƒ‰
            chunk_pos = markdown_text.find(search_content)
            
            # ì‹¤íŒ¨ ì‹œ ì§§ì€ í…ìŠ¤íŠ¸ë¡œ ì¬ì‹œë„
            if chunk_pos < 0 and len(search_content) > 50:
                search_content = search_content[:50]
                chunk_pos = markdown_text.find(search_content)
            
            if chunk_pos < 0:
                logger.warning(
                    f"âš ï¸ ì²­í¬ {chunk.chunk_index} ìœ„ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ. "
                    f"ê²€ìƒ‰ í…ìŠ¤íŠ¸ ì• 50ì: '{search_content[:50]}'"
                )
                fail_count += 1
                continue
            
            # ì²­í¬ë³´ë‹¤ ì•ì— ìˆëŠ” ê°€ì¥ ê°€ê¹Œìš´ í˜ì´ì§€ ì°¾ê¸°
            current_page = None
            for page_info in reversed(page_positions):
                if page_info['position'] <= chunk_pos:
                    current_page = page_info['vision_page_number']
                    break
            
            # í˜ì´ì§€ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°, ì²« ë²ˆì§¸ í˜ì´ì§€ë¡œ í• ë‹¹
            if current_page is None and page_positions:
                current_page = page_positions[0]['vision_page_number']
                logger.info(
                    f"ì²­í¬ {chunk.chunk_index}ê°€ ì²« í˜ì´ì§€ë³´ë‹¤ ì•ì— ìˆìŒ. "
                    f"ì²« í˜ì´ì§€({current_page})ë¡œ í• ë‹¹"
                )
            
            # í• ë‹¹
            chunk.page_number = current_page
            
            if current_page:
                success_count += 1
                logger.debug(
                    f"âœ… Chunk {chunk.chunk_index}: Vision page {current_page} "
                    f"(chunk_pos={chunk_pos})"
                )
            else:
                logger.warning(
                    f"âš ï¸ ì²­í¬ {chunk.chunk_index}ì˜ í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ. "
                    f"chunk_pos={chunk_pos}"
                )
                fail_count += 1
        
        # í†µê³„
        logger.info(f"=== page_number í• ë‹¹ ì™„ë£Œ ===")
        logger.info(f"âœ… ì„±ê³µ: {success_count}ê°œ")
        logger.info(f"âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
        if chunks:
            logger.info(f"ğŸ“Š ì„±ê³µë¥ : {success_count}/{len(chunks)} ({success_count*100/len(chunks):.1f}%)")
        
        return chunks
    
    async def _chunk_and_embed(
        self,
        markdown_text: str,
        document_id: int,
        db_session = None,
        pages_info: List[Dict] = None
    ) -> Dict:
        """
        Markdown í…ìŠ¤íŠ¸ë¥¼ ì²­í‚¹í•˜ê³  ì„ë² ë”©ì„ ìƒì„±í•˜ë©°, DBì— ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            markdown_text: Markdown í…ìŠ¤íŠ¸
            document_id: ë¬¸ì„œ ID
            db_session: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ (optional)
            pages_info: Visionì˜ í˜ì´ì§€ ì •ë³´ (page_number í¬í•¨)
        
        Returns:
            ì²­í‚¹ ë° ì„ë² ë”© ê²°ê³¼
        """
        logger.info("ì²­í‚¹ ë° ì„ë² ë”© ì‹œì‘")
        
        # 1. í…ìŠ¤íŠ¸ ì²­í‚¹
        logger.info("Step 1: í…ìŠ¤íŠ¸ ì²­í‚¹")
        chunks = self.chunker.chunk_markdown(
            markdown_text,
            document_id=document_id,
            extract_metadata=True
        )
        
        # 2. Vision page_number í• ë‹¹
        if pages_info:
            logger.info("Step 2: Vision page_number í• ë‹¹")
            chunks = self._assign_vision_page_numbers(chunks, markdown_text, pages_info)
        
        # 3. ì„ë² ë”© ìƒì„±
        logger.info("Step 3: ì„ë² ë”© ìƒì„±")
        chunks_with_embeddings = await self.embedding_service.create_chunk_embeddings(chunks)
        
        # 4. DB ì €ì¥ (ì„¸ì…˜ì´ ì œê³µëœ ê²½ìš°)
        saved_count = 0
        if db_session:
            logger.info("Step 4: ë²¡í„° DB ì €ì¥")
            from services.chunk_repository import ChunkRepository
            chunk_repo = ChunkRepository(db_session)
            
            try:
                saved_chunks = await chunk_repo.save_chunks(
                    chunks_with_embeddings,
                    document_id
                )
                saved_count = len(saved_chunks)
                logger.info(f"âœ… DB ì €ì¥ ì™„ë£Œ: {saved_count}ê°œ ì²­í¬")
            except Exception as e:
                logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
                logger.exception("ìƒì„¸ ì˜¤ë¥˜:")
                # DB ì €ì¥ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ ìƒìœ„ì—ì„œ ì²˜ë¦¬
                raise Exception(f"ì²­í¬ DB ì €ì¥ ì‹¤íŒ¨: {e}")
        else:
            logger.warning("DB ì„¸ì…˜ì´ ì œê³µë˜ì§€ ì•Šì•„ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        
        # 5. ê²°ê³¼ ë°˜í™˜
        return {
            'total_chunks': len(chunks_with_embeddings),
            'text_chunks': sum(1 for c in chunks_with_embeddings if c.chunk_type == 'text'),
            'table_chunks': sum(1 for c in chunks_with_embeddings if c.chunk_type == 'table'),
            'total_tokens': sum(c.token_count for c in chunks_with_embeddings),
            'saved_to_db': saved_count > 0,
            'saved_count': saved_count,
            'chunks': [
                {
                    'chunk_index': c.chunk_index,
                    'chunk_type': c.chunk_type,
                    'content_preview': c.content[:100] + '...' if len(c.content) > 100 else c.content,
                    'token_count': c.token_count,
                    'page_number': c.page_number,
                    'pdf_page_number': c.pdf_page_number,
                    'section_title': c.section_title,
                    'clause_number': c.clause_number,
                    'has_embedding': 'embedding' in (c.metadata or {})
                }
                for c in chunks_with_embeddings
            ]
        }


# ë³´í—˜ì•½ê´€ ê¸°ë°˜ Agentic AI ì‹œìŠ¤í…œ - ê¸°ìˆ  ì—°êµ¬ ë³´ê³ ì„œ v2.0

**ì‘ì„±ì¼**: 2025ë…„ 10ì›” 27ì¼  
**í”„ë¡œì íŠ¸ëª…**: ISPL (Insurance Policy) - Agentic AI System  
**ë²„ì „**: 2.0 (Production-Ready)

---

## ğŸ“‹ ëª©ì°¨

1. [í”„ë¡œì íŠ¸ ê°œìš”](#1-í”„ë¡œì íŠ¸-ê°œìš”)
2. [ê¸°ìˆ  ìŠ¤íƒ ë° ë²„ì „](#2-ê¸°ìˆ -ìŠ¤íƒ-ë°-ë²„ì „)
3. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#3-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
4. [LangGraph Multi-Agent ì‹œìŠ¤í…œ](#4-langgraph-multi-agent-ì‹œìŠ¤í…œ)
5. [PDF í•˜ì´ë¸Œë¦¬ë“œ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸](#5-pdf-í•˜ì´ë¸Œë¦¬ë“œ-ì „ì²˜ë¦¬-íŒŒì´í”„ë¼ì¸)
6. [í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ](#6-í•˜ì´ë¸Œë¦¬ë“œ-ê²€ìƒ‰-ì‹œìŠ¤í…œ)
7. [ë‹µë³€ ìƒì„± ë° ê²€ì¦](#7-ë‹µë³€-ìƒì„±-ë°-ê²€ì¦)
8. [ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„](#8-ë°ì´í„°ë² ì´ìŠ¤-ì„¤ê³„)
9. [Frontend êµ¬í˜„](#9-frontend-êµ¬í˜„)
10. [ì„±ëŠ¥ ìµœì í™”](#10-ì„±ëŠ¥-ìµœì í™”)
11. [í…ŒìŠ¤íŠ¸ ë° ê²€ì¦](#11-í…ŒìŠ¤íŠ¸-ë°-ê²€ì¦)
12. [ìš´ì˜ ë° ëª¨ë‹ˆí„°ë§](#12-ìš´ì˜-ë°-ëª¨ë‹ˆí„°ë§)
13. [ê¸°ìˆ ì  ê³¼ì œ ë° í•´ê²° ë°©ì•ˆ](#13-ê¸°ìˆ ì -ê³¼ì œ-ë°-í•´ê²°-ë°©ì•ˆ)
14. [í–¥í›„ ê°œì„  ë°©í–¥](#14-í–¥í›„-ê°œì„ -ë°©í–¥)

---

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### 1.1 ëª©ì 

ìƒì„±í˜• AIë¥¼ í™œìš©í•œ ë³´í—˜ì•½ê´€ ì§€ëŠ¥í˜• ê²€ìƒ‰ ë° ìƒë‹´ ì‹œìŠ¤í…œ êµ¬ì¶•:
- ë³´í—˜ì•½ê´€ PDFì˜ ìë™ ì „ì²˜ë¦¬ ë° ë²¡í„°í™”
- ìì—°ì–´ ì§ˆì˜ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ ì œê³µ
- í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€ë¥¼ í†µí•œ ì‹ ë¢°ë„ ë†’ì€ ì‘ë‹µ
- ì‚¬ìš©ì ì¹œí™”ì ì¸ ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤

### 1.2 í•µì‹¬ ê¸°ëŠ¥

**ì•½ê´€ ê´€ë¦¬**
- PDF ì—…ë¡œë“œ ë° í•˜ì´ë¸Œë¦¬ë“œ ì „ì²˜ë¦¬ (PyMuPDF + GPT-4 Vision)
- ìë™ ì²­í‚¹ ë° ë²¡í„° ì„ë² ë”©
- ì•½ê´€ ëª©ë¡ ì¡°íšŒ, ë‹¤ìš´ë¡œë“œ, ì‚­ì œ

**ì•½ê´€ ê²€ìƒ‰**
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + í‚¤ì›Œë“œ)
- ì¿¼ë¦¬ ì „ì²˜ë¦¬ ë° ì „ë¬¸ìš©ì–´ í‘œì¤€í™”
- ì»¨í…ìŠ¤íŠ¸ íŒë‹¨ ë° ì²­í¬ í™•ì¥
- RRF(Reciprocal Rank Fusion) ê¸°ë°˜ ê²°ê³¼ ìœµí•©

**ë‹µë³€ ìƒì„±**
- RAG(Retrieval-Augmented Generation) ê¸°ë°˜ ë‹µë³€
- 4ë‹¨ê³„ ê²€ì¦ (í• ë£¨ì‹œë„¤ì´ì…˜, ì»¨í…ìŠ¤íŠ¸, ì¡°í•­, í˜•ì‹)
- ì°¸ì¡° ì¶œì²˜ ìë™ ì¸ìš©
- ëŒ€í™” ì´ë ¥ ê´€ë¦¬

### 1.3 êµ¬í˜„ ë²”ìœ„

- âœ… ë°±ì—”ë“œ: FastAPI + LangGraph Multi-Agent ì‹œìŠ¤í…œ
- âœ… í”„ë¡ íŠ¸ì—”ë“œ: Next.js 15 + React 18 + Tailwind CSS
- âœ… ë°ì´í„°ë² ì´ìŠ¤: PostgreSQL 17.6 + pgvector
- âœ… AI/ML: OpenAI GPT-4, GPT-4 Vision, text-embedding-3-large
- âœ… PDF ì²˜ë¦¬: PyMuPDF4LLM + pdf2image + Vision
- âœ… ê²€ìƒ‰: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + Full-Text Search)
- âœ… ê²€ì¦: ë‹µë³€ ì‹ ë¢°ë„ 4ë‹¨ê³„ ê²€ì¦ ì‹œìŠ¤í…œ

---

## 2. ê¸°ìˆ  ìŠ¤íƒ ë° ë²„ì „

### 2.1 Backend

```python
# Core Framework
fastapi==0.115.0
uvicorn[standard]==0.32.0
python-multipart==0.0.12

# Database
sqlalchemy==2.0.35
asyncpg==0.30.0
psycopg2-binary==2.9.10
pgvector==0.3.6

# AI/ML
openai==1.55.3
langchain==0.3.7
langchain-openai==0.2.8
langchain-community==0.3.5
langgraph>=0.3.27

# PDF Processing
PyMuPDF==1.24.14
pymupdf4llm==0.0.17
pdf2image==1.17.0
Pillow==11.0.0
opencv-python==4.10.0.84

# Utilities
tiktoken==0.8.0           # í† í° ì¹´ìš´íŒ…
tenacity==9.0.0           # ì¬ì‹œë„ ë¡œì§
kiwipiepy==0.21.0         # í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„
pydantic==2.10.2
python-dotenv==1.0.1
```

### 2.2 Frontend

```json
{
  "dependencies": {
    "next": "15.0.3",
    "react": "^18.3.1",
    "react-dom": "^18.3.1",
    "react-markdown": "^9.0.1",
    "remark-gfm": "^4.0.0"
  },
  "devDependencies": {
    "typescript": "^5.6.3",
    "tailwindcss": "^3.4.14",
    "@types/react": "^19.0.0"
  }
}
```

### 2.3 Database

- **PostgreSQL**: 17.6
- **Extensions**: pgvector (ë²¡í„° ê²€ìƒ‰)
- **ì¸ë±ì‹±**: HNSW (m=32, ef_construction=200)
- **ì—°ê²° ë°©ì‹**: asyncpg (ë¹„ë™ê¸°)

### 2.4 AI Models

| ìš©ë„ | ëª¨ë¸ | ì„¤ì • |
|-----|------|------|
| ë‹µë³€ ìƒì„± | GPT-4o | temperature=0.1 |
| Vision ì²˜ë¦¬ | GPT-4 Vision | max_tokens=4000 |
| ì„ë² ë”© | text-embedding-3-large | dimension=1536 |
| ê²€ì¦ | GPT-4o | temperature=0.0 |

---

## 3. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 3.1 ì „ì²´ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ì‚¬ìš©ì (Browser)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Frontend (Next.js 15)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Chat UI     â”‚  Documents   â”‚  History             â”‚    â”‚
â”‚  â”‚  (GPT Style) â”‚  Management  â”‚  Management          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP/REST API
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI Backend                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              API Endpoints                           â”‚   â”‚
â”‚  â”‚  /chat, /search, /documents, /history               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                        â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚        LangGraph Multi-Agent System                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚  â”‚  Router  â”‚  Search  â”‚  Answer  â”‚  Mgmt    â”‚     â”‚   â”‚
â”‚  â”‚  â”‚  Agent   â”‚  Agent   â”‚  Agent   â”‚  Agent   â”‚     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚  â”‚  Context Judgement + Chunk Expansion     â”‚      â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚               â”‚               â”‚
         â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL  â”‚ â”‚   OpenAI     â”‚ â”‚  File System â”‚
â”‚  + pgvector  â”‚ â”‚     API      â”‚ â”‚   (uploads)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 ë°ì´í„° íë¦„

**PDF ì—…ë¡œë“œ í”Œë¡œìš°**
```
PDF Upload â†’ Processing Agent â†’ PyMuPDF + Vision â†’ Merge â†’ 
Chunking â†’ Embedding â†’ PostgreSQL + File System
```

**ê²€ìƒ‰ í”Œë¡œìš°**
```
User Query â†’ Router â†’ Search Agent â†’ Hybrid Search â†’ 
Context Judgement â†’ (Chunk Expansion) â†’ Answer Agent â†’ 
Validation â†’ Response
```

### 3.3 ì£¼ìš” íŠ¹ì§•

1. **ë¹„ë™ê¸° ì²˜ë¦¬**: FastAPI + asyncpgë¡œ ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ì²˜ë¦¬
2. **Multi-Agent**: LangGraphë¡œ ì‘ì—… ë¶„ë¦¬ ë° ì›Œí¬í”Œë¡œìš° ê´€ë¦¬
3. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: ë²¡í„° + í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ
4. **4ë‹¨ê³„ ê²€ì¦**: í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€ ë° ì‹ ë¢°ë„ ë³´ì¥
5. **ì»¨í…ìŠ¤íŠ¸ í™•ì¥**: ë¶ˆì¶©ë¶„í•œ ê²½ìš° ìë™ìœ¼ë¡œ ì²­í¬ í™•ì¥

---

## 4. LangGraph Multi-Agent ì‹œìŠ¤í…œ

### 4.1 Agent êµ¬ì„±

#### 4.1.1 Router Agent (ë¼ìš°í„°)

**ì—­í• **: ì‚¬ìš©ì ìš”ì²­ ë¶„ì„ ë° ì ì ˆí•œ Agentë¡œ ë¼ìš°íŒ…

**êµ¬í˜„**:
```python
from langgraph.graph import StateGraph, START
from langgraph.types import Command

def router_node(state: ISPLState):
    """
    ì‚¬ìš©ì ì§ˆì˜ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ Agentë¡œ ë¼ìš°íŒ…
    - search: ì•½ê´€ ê²€ìƒ‰ ë° ì§ˆì˜ì‘ë‹µ
    - upload: PDF ì—…ë¡œë“œ ë° ì „ì²˜ë¦¬
    - manage: ì•½ê´€ ê´€ë¦¬ (ì¡°íšŒ/ì‚­ì œ)
    """
    query = state.get("query", "")
    
    # ì˜ë„ ë¶„ë¥˜ ë¡œì§
    if "ì—…ë¡œë“œ" in query or "ë“±ë¡" in query:
        return Command(goto="processing_agent", update={"task_type": "upload"})
    elif "ì‚­ì œ" in query or "ëª©ë¡" in query:
        return Command(goto="management_agent", update={"task_type": "manage"})
    else:
        return Command(goto="search_agent", update={"task_type": "search"})
```

**íŠ¹ì§•**:
- LangGraph Command ê°ì²´ë¡œ ë™ì  ë¼ìš°íŒ…
- í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜
- ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ í†µí•œ ì •ë³´ ì „ë‹¬

#### 4.1.2 Search Agent (ê²€ìƒ‰)

**ì—­í• **: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰

**êµ¬í˜„**:
```python
async def search_node(state: ISPLState):
    """
    ë²¡í„° + í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
    - Query Preprocessing: ì „ë¬¸ìš©ì–´ í‘œì¤€í™”
    - Hybrid Search: RRF ê¸°ë°˜ ê²°ê³¼ ìœµí•©
    - Top 10 chunks ë°˜í™˜
    """
    query = state.get("query", "")
    
    # ì¿¼ë¦¬ ì „ì²˜ë¦¬
    preprocessed = query_preprocessor.preprocess(query)
    
    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    results = await hybrid_search_service.search(
        session=db_session,
        query=preprocessed.standardized_query,
        limit=10,
        similarity_threshold=0.7
    )
    
    return {"search_results": results}
```

**íŠ¹ì§•**:
- ì¿¼ë¦¬ ì „ì²˜ë¦¬ (ì „ë¬¸ìš©ì–´ í‘œì¤€í™”, í‚¤ì›Œë“œ ì¶”ì¶œ)
- ë²¡í„° ê²€ìƒ‰ + í‚¤ì›Œë“œ ê²€ìƒ‰ ë³‘ë ¬ ìˆ˜í–‰
- RRFë¡œ ê²°ê³¼ ìœµí•© ë° ì¬ìˆœìœ„í™”

#### 4.1.3 Context Judgement Agent (ì»¨í…ìŠ¤íŠ¸ íŒë‹¨)

**ì—­í• **: ê²€ìƒ‰ ê²°ê³¼ê°€ ì§ˆì˜ ì‘ë‹µì— ì¶©ë¶„í•œì§€ íŒë‹¨

**êµ¬í˜„**:
```python
async def context_judgement_node(state: ISPLState):
    """
    ê²€ìƒ‰ ê²°ê³¼ì˜ ì¶©ë¶„ì„± íŒë‹¨
    - ìµœì†Œ 3ê°œ ì´ìƒì˜ ê´€ë ¨ ì²­í¬
    - í‰ê·  ìœ ì‚¬ë„ 0.75 ì´ìƒ
    - ì´ í† í° ìˆ˜ 500 ì´ìƒ
    """
    results = state.get("search_results", [])
    
    # íŒë‹¨ ë¡œì§
    is_sufficient = (
        len(results) >= 3 and
        avg_similarity(results) >= 0.75 and
        total_tokens(results) >= 500
    )
    
    return {"context_sufficient": is_sufficient}
```

**íŠ¹ì§•**:
- ì •ëŸ‰ì  ì§€í‘œ ê¸°ë°˜ íŒë‹¨
- ë¶ˆì¶©ë¶„ ì‹œ Chunk Expansion Agentë¡œ ë¼ìš°íŒ…
- ìµœëŒ€ 2íšŒ í™•ì¥ ì œí•œ

#### 4.1.4 Chunk Expansion Agent (ì²­í¬ í™•ì¥)

**ì—­í• **: ì»¨í…ìŠ¤íŠ¸ ë¶ˆì¶©ë¶„ ì‹œ ì¸ì ‘ ì²­í¬ í™•ì¥

**êµ¬í˜„**:
```python
async def chunk_expansion_node(state: ISPLState):
    """
    ì¸ì ‘ ì²­í¬ë¥¼ í™•ì¥í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ë³´ê°•
    - ìƒìœ„ 5ê°œ ì²­í¬ì— ëŒ€í•´ Â±1 ì²­í¬ í™•ì¥
    - ì¤‘ë³µ ì œê±°
    - ì¬íŒë‹¨ì„ ìœ„í•´ Context Judgementë¡œ ë³µê·€
    """
    original_chunks = state.get("search_results", [])
    
    # ìƒìœ„ 5ê°œ í™•ì¥
    expanded = await chunk_repository.expand_chunks(
        original_chunks[:5],
        expansion_size=1
    )
    
    return {
        "search_results": expanded,
        "expansion_count": state.get("expansion_count", 0) + 1
    }
```

**íŠ¹ì§•**:
- ë¬¸ì„œ ìˆœì„œ ë³´ì¡´
- í˜ì´ì§€ ê²½ê³„ ê³ ë ¤
- ìµœëŒ€ 2íšŒ í™•ì¥ìœ¼ë¡œ ë¬´í•œ ë£¨í”„ ë°©ì§€

#### 4.1.5 Answer Agent (ë‹µë³€)

**ì—­í• **: RAG ê¸°ë°˜ ë‹µë³€ ìƒì„± ë° ê²€ì¦

**êµ¬í˜„**:
```python
async def answer_node(state: ISPLState):
    """
    GPT-4 ê¸°ë°˜ ë‹µë³€ ìƒì„± ë° 4ë‹¨ê³„ ê²€ì¦
    - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ë³´í—˜ì•½ê´€ ì „ë¬¸ê°€
    - Temperature: 0.1 (ì •í™•ë„ ìš°ì„ )
    - ê²€ì¦: í• ë£¨ì‹œë„¤ì´ì…˜, ì»¨í…ìŠ¤íŠ¸, ì¡°í•­, í˜•ì‹
    """
    query = state.get("query", "")
    context_chunks = state.get("search_results", [])
    
    # ë‹µë³€ ìƒì„±
    answer = await generate_answer(query, context_chunks)
    
    # 4ë‹¨ê³„ ê²€ì¦
    validation = await answer_validator.validate(
        answer, query, context_chunks
    )
    
    # ì‹ ë¢°ë„ 0.7 ë¯¸ë§Œ ì‹œ ì¬ìƒì„±
    if validation.overall_score < 0.7:
        answer = await regenerate_answer(query, context_chunks, validation)
    
    return {"final_answer": answer, "validation": validation}
```

**íŠ¹ì§•**:
- êµ¬ì¡°í™”ëœ ë‹µë³€ í˜•ì‹ (ğŸ“Œ ë‹µë³€, ğŸ“‹ ê´€ë ¨ ì•½ê´€, âš ï¸ ì£¼ì˜ì‚¬í•­)
- ì°¸ì¡° ë²ˆí˜¸ ìë™ ì¸ìš© [ì°¸ì¡° 1], [ì°¸ì¡° 2]
- ì‹ ë¢°ë„ ì ìˆ˜ ê¸°ë°˜ ì¬ìƒì„±

#### 4.1.6 Processing Agent (ì „ì²˜ë¦¬)

**ì—­í• **: PDF ì—…ë¡œë“œ ë° í•˜ì´ë¸Œë¦¬ë“œ ì „ì²˜ë¦¬

**êµ¬í˜„**:
```python
async def processing_node(state: ISPLState):
    """
    PDF í•˜ì´ë¸Œë¦¬ë“œ ì „ì²˜ë¦¬
    - Path 1: PyMuPDF4LLM (ë¹ ë¥¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ)
    - Path 2: GPT-4 Vision (ì´ë¯¸ì§€ ê¸°ë°˜ ì¶”ì¶œ)
    - Merge: ìœ ì‚¬ë„ ê¸°ë°˜ ë³‘í•©
    - Chunking: 1000ì, 100ì ì˜¤ë²„ë©
    - Embedding: text-embedding-3-large
    """
    pdf_path = state.get("file_path")
    
    result = await pdf_processor.process_pdf(
        pdf_path=pdf_path,
        method="pymupdf",  # ê¸°ë³¸ê°’: PyMuPDFë§Œ ì‚¬ìš©
        enable_chunking=True
    )
    
    return {"task_results": result}
```

**íŠ¹ì§•**:
- 3ê°€ì§€ ì²˜ë¦¬ ëª¨ë“œ: pymupdf, vision, both
- í’ˆì§ˆ ê²€ì¦ ë‹¨ê³„ í¬í•¨
- ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬

#### 4.1.7 Management Agent (ê´€ë¦¬)

**ì—­í• **: ì•½ê´€ ê´€ë¦¬ (ì¡°íšŒ, ì‚­ì œ, ë‹¤ìš´ë¡œë“œ)

**êµ¬í˜„**:
```python
async def management_node(state: ISPLState):
    """
    ì•½ê´€ ê´€ë¦¬ ì‘ì—… ìˆ˜í–‰
    - ëª©ë¡ ì¡°íšŒ
    - íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    - ë¬¸ì„œ ì‚­ì œ
    """
    task_type = state.get("management_task", "list")
    
    if task_type == "list":
        documents = await document_service.list_documents()
    elif task_type == "delete":
        await document_service.delete_document(document_id)
    
    return {"task_results": documents}
```

### 4.2 ê·¸ë˜í”„ êµ¬ì¡°

```python
builder = StateGraph(ISPLState)

# ë…¸ë“œ ì¶”ê°€
builder.add_node("router", router_node)
builder.add_node("search_agent", search_node)
builder.add_node("context_judgement_agent", context_judgement_node)
builder.add_node("chunk_expansion_agent", chunk_expansion_node)
builder.add_node("answer_agent", answer_node)
builder.add_node("processing_agent", processing_node)
builder.add_node("management_agent", management_node)

# ì—£ì§€ ì„¤ì •
builder.add_edge(START, "router")
builder.add_edge("search_agent", "context_judgement_agent")

# ì¡°ê±´ë¶€ ë¼ìš°íŒ…
builder.add_conditional_edges(
    "context_judgement_agent",
    route_after_judgement,  # ì¶©ë¶„ â†’ answer_agent, ë¶ˆì¶©ë¶„ â†’ chunk_expansion
    {"answer_agent": "answer_agent", "chunk_expansion_agent": "chunk_expansion_agent"}
)

builder.add_edge("chunk_expansion_agent", "context_judgement_agent")
builder.add_edge("answer_agent", END)
builder.add_edge("processing_agent", END)
builder.add_edge("management_agent", END)

graph = builder.compile(checkpointer=MemorySaver())
```

### 4.3 State ê´€ë¦¬

```python
class ISPLState(MessagesState):
    """LangGraph ìƒíƒœ ì •ì˜"""
    
    # ê¸°ë³¸ ì •ë³´
    query: str                      # ì‚¬ìš©ì ì§ˆì˜
    task_type: str                  # ì‘ì—… ìœ í˜• (search/upload/manage)
    
    # ê²€ìƒ‰ ê²°ê³¼
    search_results: List[dict]      # ê²€ìƒ‰ëœ ì²­í¬ ëª©ë¡
    expanded_chunks: List[dict]     # í™•ì¥ëœ ì²­í¬
    
    # ì»¨í…ìŠ¤íŠ¸ íŒë‹¨
    context_sufficient: bool        # ì»¨í…ìŠ¤íŠ¸ ì¶©ë¶„ ì—¬ë¶€
    expansion_count: int            # í™•ì¥ íšŸìˆ˜
    
    # ë‹µë³€
    final_answer: str               # ìµœì¢… ë‹µë³€
    validation: dict                # ê²€ì¦ ê²°ê³¼
    
    # ì—ëŸ¬ ì²˜ë¦¬
    error: Optional[str]            # ì—ëŸ¬ ë©”ì‹œì§€
    task_results: dict              # ì‘ì—… ê²°ê³¼
```

---

## 5. PDF í•˜ì´ë¸Œë¦¬ë“œ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

### 5.1 ì „ì²´ í”„ë¡œì„¸ìŠ¤

```
PDF ì…ë ¥
   â”‚
   â”œâ”€ Path 1: PyMuPDF4LLM
   â”‚    â”œâ”€ ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ
   â”‚    â”œâ”€ Markdown ë³€í™˜
   â”‚    â””â”€ í‘œ/ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
   â”‚
   â”œâ”€ Path 2: GPT-4 Vision (ì„ íƒì )
   â”‚    â”œâ”€ PDF â†’ ì´ë¯¸ì§€ (DPI 300)
   â”‚    â”œâ”€ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ê·¸ë ˆì´ìŠ¤ì¼€ì¼, ë…¸ì´ì¦ˆ ì œê±°)
   â”‚    â””â”€ Vision API í˜¸ì¶œ
   â”‚
   â”œâ”€ Merge (Path 1 + Path 2)
   â”‚    â”œâ”€ í˜ì´ì§€ë³„ ì •ë ¬
   â”‚    â”œâ”€ ìœ ì‚¬ë„ ê¸°ë°˜ ì¤‘ë³µ ì œê±°
   â”‚    â””â”€ ìµœì¢… ë³‘í•©
   â”‚
   â”œâ”€ Quality Validation
   â”‚    â”œâ”€ ì™„ì „ì„± ê²€ì‚¬
   â”‚    â”œâ”€ ì¼ê´€ì„± ê²€ì‚¬
   â”‚    â””â”€ í’ˆì§ˆ ì ìˆ˜ ì‚°ì¶œ
   â”‚
   â”œâ”€ Chunking
   â”‚    â”œâ”€ Fixed-size: 1000ì, 100ì ì˜¤ë²„ë©
   â”‚    â”œâ”€ í‘œ: ì „ì²´ ë‹¨ìœ„
   â”‚    â””â”€ ì´ë¯¸ì§€: ì„¤ëª… + ì£¼ë³€ í…ìŠ¤íŠ¸
   â”‚
   â”œâ”€ Embedding
   â”‚    â”œâ”€ text-embedding-3-large
   â”‚    â”œâ”€ 1536 ì°¨ì›
   â”‚    â””â”€ ë°°ì¹˜ ì²˜ë¦¬ (100ê°œì”©)
   â”‚
   â””â”€ Storage
        â”œâ”€ PostgreSQL: ë©”íƒ€ë°ì´í„° + ë²¡í„°
        â””â”€ File System: ì›ë³¸ PDF + Markdown
```

### 5.2 Path 1: PyMuPDF4LLM

**ì¥ì **:
- ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ (í˜ì´ì§€ë‹¹ ~0.1ì´ˆ)
- ì •í™•í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
- í‘œ êµ¬ì¡° ë³´ì¡´
- ë¹„ìš© ì—†ìŒ

**êµ¬í˜„**:
```python
class PyMuPDFExtractor:
    def extract(self, pdf_path: str) -> Dict:
        """PyMuPDF4LLMìœ¼ë¡œ Markdown ë³€í™˜"""
        md_text = pymupdf4llm.to_markdown(
            pdf_path,
            page_chunks=True,  # í˜ì´ì§€ë³„ ë¶„ë¦¬
            write_images=True,  # ì´ë¯¸ì§€ ì¶”ì¶œ
            image_path="uploads/images"
        )
        
        return {
            "markdown": md_text,
            "pages": self._parse_pages(md_text),
            "quality_score": self._calculate_quality(md_text)
        }
```

### 5.3 Path 2: GPT-4 Vision (ì„ íƒì )

**ì¥ì **:
- ë³µì¡í•œ ë ˆì´ì•„ì›ƒ ì²˜ë¦¬
- ì†ê¸€ì”¨/ì €í™”ì§ˆ ë¬¸ì„œ ì²˜ë¦¬
- ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ ì¸ì‹
- í‘œ êµ¬ì¡° ë³µì›

**ë‹¨ì **:
- ëŠë¦° ì²˜ë¦¬ ì†ë„ (í˜ì´ì§€ë‹¹ ~10ì´ˆ)
- API ë¹„ìš© ë°œìƒ ($0.01/í˜ì´ì§€)

**êµ¬í˜„**:
```python
class VisionExtractor:
    async def extract(self, pdf_path: str) -> Dict:
        """GPT-4 Visionìœ¼ë¡œ ì´ë¯¸ì§€ ê¸°ë°˜ ì¶”ì¶œ"""
        # PDF â†’ ì´ë¯¸ì§€ ë³€í™˜
        images = convert_from_path(pdf_path, dpi=300)
        
        results = []
        for idx, img in enumerate(images):
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_img = self._preprocess_image(img)
            
            # Vision API í˜¸ì¶œ
            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=[{
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "ì´ ë³´í—˜ ì•½ê´€ í˜ì´ì§€ì˜ ëª¨ë“  ë‚´ìš©ì„ Markdownìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”."
                        },
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:image/png;base64,{base64_img}"}
                        }
                    ]
                }]
            )
            
            results.append(response.choices[0].message.content)
        
        return {"markdown": "\n\n".join(results), "pages": results}
```

### 5.4 Hybrid Merger

**ë³‘í•© ì „ëµ**:
1. í˜ì´ì§€ë³„ë¡œ Path 1ê³¼ Path 2 ê²°ê³¼ ì •ë ¬
2. SequenceMatcherë¡œ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°
3. ìœ ì‚¬ë„ 0.8 ì´ìƒ: Path 1 ì‚¬ìš© (ë¹ ë¥´ê³  ì •í™•)
4. ìœ ì‚¬ë„ 0.8 ë¯¸ë§Œ: Path 2 ì‚¬ìš© (Visionì´ ë” ì •í™•)
5. í‘œ/ì´ë¯¸ì§€: ë‘ ê²½ë¡œ ê²°ê³¼ ë³‘í•©

**êµ¬í˜„**:
```python
class HybridMerger:
    def merge(self, pymupdf_result: Dict, vision_result: Dict) -> Dict:
        """ë‘ ê²½ë¡œì˜ ê²°ê³¼ë¥¼ ë³‘í•©"""
        merged_pages = []
        
        for i in range(len(pymupdf_result["pages"])):
            pymupdf_page = pymupdf_result["pages"][i]
            vision_page = vision_result["pages"][i]
            
            # ìœ ì‚¬ë„ ê³„ì‚°
            similarity = self._calculate_similarity(pymupdf_page, vision_page)
            
            if similarity >= 0.8:
                merged_pages.append(pymupdf_page)  # PyMuPDF ìš°ì„ 
            else:
                merged_pages.append(vision_page)   # Vision ìš°ì„ 
        
        return {"markdown": "\n\n".join(merged_pages)}
```

### 5.5 Chunking ì „ëµ

**Fixed-size Chunking**:
```python
class TextChunker:
    def __init__(self, chunk_size=1000, overlap=100):
        self.chunk_size = chunk_size
        self.overlap = overlap
        self.encoding = tiktoken.get_encoding("cl100k_base")
    
    def chunk_text(self, text: str, metadata: dict) -> List[dict]:
        """í…ìŠ¤íŠ¸ë¥¼ ê³ ì • í¬ê¸°ë¡œ ì²­í‚¹"""
        tokens = self.encoding.encode(text)
        chunks = []
        
        start = 0
        while start < len(tokens):
            end = start + self.chunk_size
            chunk_tokens = tokens[start:end]
            chunk_text = self.encoding.decode(chunk_tokens)
            
            chunks.append({
                "content": chunk_text,
                "chunk_index": len(chunks),
                "token_count": len(chunk_tokens),
                "metadata": metadata
            })
            
            start = end - self.overlap  # ì˜¤ë²„ë© ì ìš©
        
        return chunks
```

**íŠ¹ìˆ˜ ì²˜ë¦¬**:
- **í‘œ**: ì „ì²´ í‘œë¥¼ í•˜ë‚˜ì˜ ì²­í¬ë¡œ ìœ ì§€
- **ì´ë¯¸ì§€**: ALT í…ìŠ¤íŠ¸ + ì£¼ë³€ 200ì í¬í•¨
- **ì œëª©**: ì„¹ì…˜ ì œëª©ì„ ë©”íƒ€ë°ì´í„°ì— í¬í•¨

### 5.6 Embedding ìƒì„±

**ë°°ì¹˜ ì²˜ë¦¬**:
```python
class EmbeddingService:
    async def generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """ë°°ì¹˜ ì„ë² ë”© ìƒì„±"""
        batch_size = 100
        all_embeddings = []
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            
            response = await self.client.embeddings.create(
                model="text-embedding-3-large",
                input=batch,
                dimensions=1536
            )
            
            embeddings = [item.embedding for item in response.data]
            all_embeddings.extend(embeddings)
        
        return all_embeddings
```

**íŠ¹ì§•**:
- ë°°ì¹˜ í¬ê¸°: 100ê°œ (API ì œí•œ)
- ì¬ì‹œë„ ë¡œì§: tenacity í™œìš©
- ìºì‹±: Redis í™œìš© (ì„ íƒì )

---

## 6. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ

### 6.1 ê²€ìƒ‰ ì „ëµ

```
User Query
   â”‚
   â”œâ”€ Query Preprocessing
   â”‚    â”œâ”€ ì „ë¬¸ìš©ì–´ í‘œì¤€í™”
   â”‚    â”œâ”€ ê³µë°± ì •ê·œí™”
   â”‚    â””â”€ í‚¤ì›Œë“œ ì¶”ì¶œ
   â”‚
   â”œâ”€ Parallel Search
   â”‚    â”‚
   â”‚    â”œâ”€ Vector Search
   â”‚    â”‚    â”œâ”€ Query Embedding
   â”‚    â”‚    â”œâ”€ Cosine Similarity
   â”‚    â”‚    â””â”€ Top 10 chunks
   â”‚    â”‚
   â”‚    â””â”€ Keyword Search
   â”‚         â”œâ”€ Full-Text Search
   â”‚         â”œâ”€ ì¡°í•­ ë²ˆí˜¸ ë§¤ì¹­
   â”‚         â””â”€ Top 10 chunks
   â”‚
   â”œâ”€ RRF Fusion
   â”‚    â”œâ”€ Reciprocal Rank Fusion
   â”‚    â”œâ”€ k=60 (í‘œì¤€ê°’)
   â”‚    â””â”€ ìµœì¢… Top 10
   â”‚
   â””â”€ Context Optimization
        â”œâ”€ ìµœëŒ€ 20,000 í† í°
        â””â”€ ìœ ì‚¬ë„ 0.7 ì´ìƒ
```

### 6.2 Query Preprocessing

**ì „ë¬¸ìš©ì–´ í‘œì¤€í™”**:
```python
class QueryPreprocessor:
    def preprocess(self, query: str) -> PreprocessedQuery:
        """ì¿¼ë¦¬ ì „ì²˜ë¦¬"""
        # 1. ì •ê·œí™”
        normalized = self._normalize(query)
        
        # 2. ì „ë¬¸ìš©ì–´ í‘œì¤€í™”
        standardized = self._standardize_terms(normalized)
        
        # 3. í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = extract_keywords(standardized)
        
        # 4. ì¡°í•­ ë²ˆí˜¸ ì¶”ì¶œ
        clauses = self._extract_clause_numbers(query)
        
        return PreprocessedQuery(
            original_query=query,
            standardized_query=standardized,
            keywords=keywords,
            clause_numbers=clauses
        )
```

**ì „ë¬¸ìš©ì–´ ì‚¬ì „** (`insurance_terms.json`):
```json
{
  "synonyms": {
    "ë³´í—˜ê¸ˆ": ["ê¸‰ì—¬ê¸ˆ", "ì§€ê¸‰ê¸ˆ", "ë³´ìƒê¸ˆ"],
    "ë©´ì±…": ["ë©´ì±…ì‚¬í•­", "ë³´ìƒí•˜ì§€ ì•ŠëŠ” ì‚¬í•­"],
    "CI": ["ì¤‘ëŒ€í•œì§ˆë³‘", "Critical Illness"]
  },
  "normalization": {
    "spacing": {
      "ë³´í—˜ ê¸ˆ": "ë³´í—˜ê¸ˆ",
      "ë©´ì±… ì‚¬í•­": "ë©´ì±…ì‚¬í•­"
    }
  }
}
```

### 6.3 Vector Search

**HNSW ì¸ë±ìŠ¤ í™œìš©**:
```python
class VectorSearchService:
    async def search(
        self,
        session: AsyncSession,
        query_embedding: List[float],
        limit: int = 10,
        similarity_threshold: float = 0.7
    ) -> List[VectorSearchResult]:
        """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰"""
        query = text("""
            SELECT 
                dc.id,
                dc.content,
                dc.page_number,
                dc.clause_number,
                dc.metadata,
                d.filename,
                d.company_name,
                1 - (dc.embedding <=> :query_embedding) as similarity
            FROM document_chunks dc
            JOIN documents d ON dc.document_id = d.id
            WHERE 
                d.status = 'active' AND
                1 - (dc.embedding <=> :query_embedding) > :threshold
            ORDER BY dc.embedding <=> :query_embedding
            LIMIT :limit
        """)
        
        result = await session.execute(query, {
            "query_embedding": query_embedding,
            "threshold": similarity_threshold,
            "limit": limit
        })
        
        return [VectorSearchResult.from_row(row) for row in result]
```

**ì¸ë±ìŠ¤ ì„¤ì •**:
```sql
CREATE INDEX idx_chunks_embedding ON document_chunks 
USING hnsw (embedding vector_cosine_ops) 
WITH (m = 32, ef_construction = 200);
```

**íŒŒë¼ë¯¸í„° ì„¤ëª…**:
- `m=32`: ê° ë…¸ë“œì˜ ì—°ê²° ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì •í™•ë„â†‘, ë©”ëª¨ë¦¬â†‘)
- `ef_construction=200`: êµ¬ì¶• ì‹œ íƒìƒ‰ ë²”ìœ„ (ë†’ì„ìˆ˜ë¡ ì •í™•ë„â†‘, ì‹œê°„â†‘)
- `vector_cosine_ops`: Cosine Similarity ì‚¬ìš©

### 6.4 Keyword Search

**Full-Text Search (PostgreSQL tsvector)**:
```python
async def keyword_search(
    self,
    session: AsyncSession,
    query: str,
    limit: int = 10
) -> List[dict]:
    """í‚¤ì›Œë“œ ê²€ìƒ‰ (Full-Text Search)"""
    # tsquery ìƒì„±
    keywords = extract_keywords(query)
    tsquery_str = ' & '.join(keywords)
    
    query_sql = text("""
        SELECT 
            dc.id,
            dc.content,
            dc.page_number,
            dc.clause_number,
            ts_rank(to_tsvector('korean', dc.content), query) as rank
        FROM document_chunks dc
        WHERE to_tsvector('korean', dc.content) @@ to_tsquery('korean', :tsquery)
        ORDER BY rank DESC
        LIMIT :limit
    """)
    
    result = await session.execute(query_sql, {
        "tsquery": tsquery_str,
        "limit": limit
    })
    
    return result.fetchall()
```

**ì¡°í•­ ë²ˆí˜¸ ë§¤ì¹­**:
```python
def _match_clause_numbers(self, query: str, chunks: List[dict]) -> List[dict]:
    """ì¡°í•­ ë²ˆí˜¸ ì •í™• ë§¤ì¹­"""
    clause_numbers = re.findall(r'ì œ\s*(\d+)\s*ì¡°', query)
    
    if not clause_numbers:
        return chunks
    
    # ì¡°í•­ ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ëŠ” ì²­í¬ë¥¼ ìš°ì„  ìˆœìœ„ë¡œ
    matched = []
    for chunk in chunks:
        if chunk.get("clause_number") in clause_numbers:
            matched.append(chunk)
    
    return matched + [c for c in chunks if c not in matched]
```

### 6.5 RRF (Reciprocal Rank Fusion)

**ì•Œê³ ë¦¬ì¦˜**:
```python
class HybridSearchService:
    RRF_K = 60  # í‘œì¤€ê°’
    
    def _reciprocal_rank_fusion(
        self,
        vector_results: List[dict],
        keyword_results: List[dict]
    ) -> List[dict]:
        """RRFë¡œ ë‘ ê²€ìƒ‰ ê²°ê³¼ ìœµí•©"""
        scores = {}
        
        # Vector ê²°ê³¼ ì ìˆ˜ ê³„ì‚°
        for rank, result in enumerate(vector_results, start=1):
            chunk_id = result["id"]
            scores[chunk_id] = scores.get(chunk_id, 0) + 1 / (rank + self.RRF_K)
        
        # Keyword ê²°ê³¼ ì ìˆ˜ ê³„ì‚°
        for rank, result in enumerate(keyword_results, start=1):
            chunk_id = result["id"]
            scores[chunk_id] = scores.get(chunk_id, 0) + 1 / (rank + self.RRF_K)
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_ids = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)
        
        # ì›ë³¸ ê²°ê³¼ì—ì„œ ì²­í¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        id_to_chunk = {r["id"]: r for r in vector_results + keyword_results}
        
        return [id_to_chunk[chunk_id] for chunk_id in sorted_ids]
```

**RRF ìˆ˜ì‹**:
```
RRF(d) = Î£ 1 / (k + rank_i(d))

where:
- d: document (chunk)
- k: constant (60)
- rank_i(d): rank of d in i-th result list
```

### 6.6 Context Optimization

**í† í° ì œí•œ**:
```python
def _optimize_context(
    self,
    chunks: List[dict],
    max_tokens: int = 20000
) -> List[dict]:
    """ì»¨í…ìŠ¤íŠ¸ë¥¼ í† í° ì œí•œ ë‚´ë¡œ ìµœì í™”"""
    selected_chunks = []
    total_tokens = 0
    
    for chunk in chunks:
        chunk_tokens = chunk.get("token_count", 0)
        
        if total_tokens + chunk_tokens <= max_tokens:
            selected_chunks.append(chunk)
            total_tokens += chunk_tokens
        else:
            break
    
    logger.info(f"ì»¨í…ìŠ¤íŠ¸ ìµœì í™”: {len(chunks)} â†’ {len(selected_chunks)} chunks, {total_tokens} tokens")
    
    return selected_chunks
```

---

## 7. ë‹µë³€ ìƒì„± ë° ê²€ì¦

### 7.1 RAG ê¸°ë°˜ ë‹µë³€ ìƒì„±

**ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸**:
```python
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë³´í—˜ì•½ê´€ ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì„¸ìš”:

1. **ì •í™•ì„± ë³´ì¥**: ì œê³µëœ ì•½ê´€ ë‚´ìš©ì—ë§Œ ê¸°ë°˜í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
2. **ê·¼ê±° ì œì‹œ**: ëª¨ë“  ë‹µë³€ì— í•´ë‹¹ ì•½ê´€ ì¡°í•­ì„ ì¸ìš©í•˜ì„¸ìš”. [ì°¸ì¡° N] í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.
3. **í•œê³„ ì¸ì •**: ì œê³µëœ ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ "í•´ë‹¹ ì •ë³´ê°€ ì•½ê´€ì— ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.
4. **ëª…í™•í•œ êµ¬ì¡°**: ë‹µë³€ì„ ë‹¤ìŒ ìˆœì„œë¡œ êµ¬ì„±í•˜ì„¸ìš”:
   ğŸ“Œ ë‹µë³€: ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€
   ğŸ“‹ ê´€ë ¨ ì•½ê´€: ì°¸ì¡°í•œ ì•½ê´€ ë‚´ìš©ì„ ì¸ìš©
   âš ï¸ ì£¼ì˜ì‚¬í•­: ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ì‚¬í•­
5. **ê¸ˆì§€ì‚¬í•­**: ì¶”ì¸¡, ì¼ë°˜ ìƒì‹, ë‹¤ë¥¸ ë³´í—˜ì‚¬ ì •ë³´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
"""
```

**ë‹µë³€ ìƒì„±**:
```python
class AnswerAgent:
    async def generate_answer(
        self,
        query: str,
        context_chunks: List[dict]
    ) -> str:
        """RAG ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = self._build_context(context_chunks)
        
        # í”„ë¡¬í”„íŠ¸ ì¡°ë¦½
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": f"""
ë‹¤ìŒ ì•½ê´€ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

**ì°¸ì¡° ì•½ê´€**:
{context}

**ì§ˆë¬¸**: {query}

ë‹µë³€ í˜•ì‹:
ğŸ“Œ ë‹µë³€
[ë‹µë³€ ë‚´ìš©]

ğŸ“‹ ê´€ë ¨ ì•½ê´€
[ì°¸ì¡° 1] [ë‚´ìš©]
[ì°¸ì¡° 2] [ë‚´ìš©]

âš ï¸ ì£¼ì˜ì‚¬í•­
[ì¶”ê°€ í™•ì¸ ì‚¬í•­]
"""}
        ]
        
        # GPT-4 í˜¸ì¶œ
        response = await self.client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.1,  # ì •í™•ë„ ìš°ì„ 
            max_tokens=2000
        )
        
        return response.choices[0].message.content
```

### 7.2 4ë‹¨ê³„ ê²€ì¦ ì‹œìŠ¤í…œ

#### 7.2.1 ê²€ì¦ ê°œìš”

```
Answer Validation
   â”‚
   â”œâ”€ 1. Hallucination Check (40%)
   â”‚    â”œâ”€ GPT-4ë¡œ ë‹µë³€ vs ì»¨í…ìŠ¤íŠ¸ ê²€ì¦
   â”‚    â””â”€ ì‚¬ì‹¤ í™•ì¸
   â”‚
   â”œâ”€ 2. Context Matching (30%)
   â”‚    â”œâ”€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
   â”‚    â””â”€ ì„ë² ë”© ë¹„êµ
   â”‚
   â”œâ”€ 3. Clause Verification (20%)
   â”‚    â”œâ”€ ì¡°í•­ ë²ˆí˜¸ ì¶”ì¶œ
   â”‚    â””â”€ DB ì¡´ì¬ í™•ì¸
   â”‚
   â”œâ”€ 4. Format Validation (10%)
   â”‚    â”œâ”€ êµ¬ì¡° í™•ì¸
   â”‚    â”œâ”€ ì°¸ì¡° ë²ˆí˜¸ í™•ì¸
   â”‚    â””â”€ ì¡°í•­ ì¸ìš© í™•ì¸
   â”‚
   â””â”€ Overall Score (0.0 ~ 1.0)
        â””â”€ ê°€ì¤‘ í‰ê·  ê³„ì‚°
```

#### 7.2.2 Hallucination Check (í• ë£¨ì‹œë„¤ì´ì…˜ ê²€ì¦)

**ëª©ì **: ë‹µë³€ì´ ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ë‚´ìš©ì„ ë§Œë“¤ì–´ë‚´ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸

**êµ¬í˜„**:
```python
async def _check_hallucination(
    self,
    answer: str,
    context_chunks: List[dict]
) -> ValidationDetail:
    """GPT-4ë¡œ í• ë£¨ì‹œë„¤ì´ì…˜ ê²€ì¦"""
    context_text = "\n\n".join([c["content"] for c in context_chunks])
    
    prompt = f"""
ë‹¤ìŒ ë‹µë³€ì´ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì—ë§Œ ê¸°ë°˜í•˜ê³  ìˆëŠ”ì§€ ê²€ì¦í•˜ì„¸ìš”.

**ì»¨í…ìŠ¤íŠ¸**:
{context_text}

**ë‹µë³€**:
{answer}

ê²€ì¦ ê¸°ì¤€:
1. ë‹µë³€ì˜ ëª¨ë“  ë‚´ìš©ì´ ì»¨í…ìŠ¤íŠ¸ì— ìˆëŠ”ê°€?
2. ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ ìƒì‹ì„ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ëŠ”ê°€?
3. ë‹¤ë¥¸ ì¶œì²˜ì˜ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ëŠ”ê°€?

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:
{{
  "is_faithful": true/false,
  "confidence": 0.0~1.0,
  "issues": ["ë¬¸ì œì 1", "ë¬¸ì œì 2", ...]
}}
"""
    
    response = await self.client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.0,
        response_format={"type": "json_object"}
    )
    
    result = json.loads(response.choices[0].message.content)
    
    return ValidationDetail(
        check_name="hallucination",
        passed=result["is_faithful"],
        score=result["confidence"],
        details={"issues": result["issues"]}
    )
```

#### 7.2.3 Context Matching (ì»¨í…ìŠ¤íŠ¸ ì¼ì¹˜ë„)

**ëª©ì **: ë‹µë³€ê³¼ ì»¨í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ í™•ì¸

**êµ¬í˜„**:
```python
async def _check_context_matching(
    self,
    answer: str,
    context_chunks: List[dict]
) -> ValidationDetail:
    """ë‹µë³€ê³¼ ì»¨í…ìŠ¤íŠ¸ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
    # ë‹µë³€ ì„ë² ë”©
    answer_embedding = await self.embedding_service.generate_embedding(answer)
    
    # ê° ì²­í¬ì™€ì˜ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = []
    for chunk in context_chunks:
        chunk_embedding = chunk["embedding"]
        similarity = cosine_similarity(answer_embedding, chunk_embedding)
        similarities.append(similarity)
    
    # í‰ê·  ìœ ì‚¬ë„
    avg_similarity = sum(similarities) / len(similarities)
    
    # 0.7 ì´ìƒì´ë©´ í†µê³¼
    passed = avg_similarity >= 0.7
    
    return ValidationDetail(
        check_name="context_matching",
        passed=passed,
        score=avg_similarity,
        details={"avg_similarity": avg_similarity}
    )
```

#### 7.2.4 Clause Verification (ì¡°í•­ í™•ì¸)

**ëª©ì **: ë‹µë³€ì— ì¸ìš©ëœ ì¡°í•­ ë²ˆí˜¸ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸

**êµ¬í˜„**:
```python
async def _check_clause_verification(
    self,
    answer: str,
    session: AsyncSession
) -> ValidationDetail:
    """ì¡°í•­ ë²ˆí˜¸ ì¡´ì¬ í™•ì¸"""
    # ë‹µë³€ì—ì„œ ì¡°í•­ ë²ˆí˜¸ ì¶”ì¶œ
    clause_pattern = r'ì œ\s*(\d+)\s*ì¡°'
    mentioned_clauses = re.findall(clause_pattern, answer)
    
    if not mentioned_clauses:
        return ValidationDetail(
            check_name="clause_verification",
            passed=True,
            score=1.0,
            details={"message": "ì¡°í•­ ë²ˆí˜¸ ë¯¸ì‚¬ìš©"}
        )
    
    # DBì—ì„œ ì¡°í•­ í™•ì¸
    query = text("""
        SELECT DISTINCT clause_number
        FROM document_chunks
        WHERE clause_number IN :clauses
    """)
    
    result = await session.execute(query, {"clauses": mentioned_clauses})
    existing_clauses = [row[0] for row in result]
    
    # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¡°í•­
    invalid_clauses = set(mentioned_clauses) - set(existing_clauses)
    
    if invalid_clauses:
        return ValidationDetail(
            check_name="clause_verification",
            passed=False,
            score=0.0,
            details={"invalid_clauses": list(invalid_clauses)}
        )
    
    return ValidationDetail(
        check_name="clause_verification",
        passed=True,
        score=1.0,
        details={"verified_clauses": len(mentioned_clauses)}
    )
```

#### 7.2.5 Format Validation (í˜•ì‹ ê²€ì¦)

**ëª©ì **: ë‹µë³€ì´ ì •í•´ì§„ í˜•ì‹ì„ ë”°ë¥´ëŠ”ì§€ í™•ì¸

**êµ¬í˜„**:
```python
def _check_format(
    self,
    answer: str,
    search_results: List[dict]
) -> ValidationDetail:
    """ë‹µë³€ í˜•ì‹ ê²€ì¦"""
    checks = {
        "has_structure": False,
        "has_references": False,
        "has_clause_numbers": False
    }
    warnings = []
    
    # 1. êµ¬ì¡°í™” ì—¬ë¶€
    if "ğŸ“Œ ë‹µë³€" in answer and "ğŸ“‹ ê´€ë ¨ ì•½ê´€" in answer:
        checks["has_structure"] = True
    else:
        warnings.append("êµ¬ì¡°í™”ëœ í˜•ì‹ì´ ì—†ìŠµë‹ˆë‹¤")
    
    # 2. ì°¸ì¡° ë²ˆí˜¸
    if re.search(r'\[ì°¸ì¡°\s*\d+\]', answer):
        checks["has_references"] = True
    else:
        warnings.append("ì°¸ì¡° ë²ˆí˜¸ê°€ ì—†ìŠµë‹ˆë‹¤")
    
    # 3. ì¡°í•­ ë²ˆí˜¸ (ì„ íƒì )
    if re.search(r'ì œ\s*\d+\s*ì¡°', answer):
        checks["has_clause_numbers"] = True
    
    # ì ìˆ˜ ê³„ì‚°
    score = sum(checks.values()) / len(checks)
    
    return ValidationDetail(
        check_name="format_validation",
        passed=score >= 0.7,
        score=score,
        details={"checks": checks, "warnings": warnings}
    )
```

#### 7.2.6 ì¢…í•© ì ìˆ˜ ê³„ì‚°

```python
def validate(
    self,
    answer: str,
    query: str,
    context_chunks: List[dict],
    session: AsyncSession = None
) -> AnswerValidation:
    """4ë‹¨ê³„ ê²€ì¦ ìˆ˜í–‰"""
    # ê° ê²€ì¦ ìˆ˜í–‰
    hallucination = await self._check_hallucination(answer, context_chunks)
    context = await self._check_context_matching(answer, context_chunks)
    clause = await self._check_clause_verification(answer, session)
    format_check = self._check_format(answer, context_chunks)
    
    # ê°€ì¤‘ í‰ê·  ê³„ì‚°
    overall_score = (
        hallucination.score * self.WEIGHTS["hallucination"] +
        context.score * self.WEIGHTS["context"] +
        clause.score * self.WEIGHTS["clause"] +
        format_check.score * self.WEIGHTS["format"]
    )
    
    return AnswerValidation(
        overall_score=overall_score,
        passed=overall_score >= 0.7,
        validations=[hallucination, context, clause, format_check],
        timestamp=datetime.utcnow()
    )
```

### 7.3 ì¬ìƒì„± ë¡œì§

**ì‹ ë¢°ë„ 0.7 ë¯¸ë§Œ ì‹œ ì¬ìƒì„±**:
```python
async def generate_with_validation(
    self,
    query: str,
    context_chunks: List[dict],
    max_retries: int = 2
) -> Tuple[str, AnswerValidation]:
    """ê²€ì¦ì„ í†µê³¼í•  ë•Œê¹Œì§€ ë‹µë³€ ì¬ìƒì„±"""
    for attempt in range(max_retries):
        # ë‹µë³€ ìƒì„±
        answer = await self.generate_answer(query, context_chunks)
        
        # ê²€ì¦
        validation = await self.validator.validate(
            answer, query, context_chunks
        )
        
        # í†µê³¼ ì‹œ ë°˜í™˜
        if validation.passed:
            logger.info(f"ë‹µë³€ ê²€ì¦ í†µê³¼ (score={validation.overall_score:.2f})")
            return answer, validation
        
        # ì‹¤íŒ¨ ì‹œ í”„ë¡¬í”„íŠ¸ ê°œì„ 
        logger.warning(f"ë‹µë³€ ê²€ì¦ ì‹¤íŒ¨ (score={validation.overall_score:.2f}), ì¬ì‹œë„ {attempt+1}/{max_retries}")
        
        # ê²€ì¦ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
        feedback = self._build_feedback(validation)
        context_chunks = self._enhance_context(context_chunks, feedback)
    
    # ìµœëŒ€ ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨ ì‹œ ë§ˆì§€ë§‰ ë‹µë³€ ë°˜í™˜
    logger.error(f"ë‹µë³€ ê²€ì¦ ìµœì¢… ì‹¤íŒ¨ (score={validation.overall_score:.2f})")
    return answer, validation
```

---

## 8. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„

### 8.1 ìŠ¤í‚¤ë§ˆ êµ¬ì¡°

```sql
-- pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- ì‚¬ìš©ì í…Œì´ë¸”
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE,
    email VARCHAR(100) UNIQUE,
    full_name VARCHAR(100),
    role VARCHAR(20) DEFAULT 'user',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    filename VARCHAR(255) NOT NULL,
    original_filename VARCHAR(255) NOT NULL,
    file_path TEXT NOT NULL,
    file_size BIGINT,
    document_type VARCHAR(50) NOT NULL,
    insurance_type VARCHAR(50),
    company_name VARCHAR(100),
    status VARCHAR(20) DEFAULT 'active',
    upload_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    processed_timestamp TIMESTAMP,
    total_pages INTEGER,
    processing_status VARCHAR(20) DEFAULT 'pending'
);

-- ë²¡í„°í™”ëœ ì²­í¬
CREATE TABLE document_chunks (
    id SERIAL PRIMARY KEY,
    document_id INTEGER NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    chunk_index INTEGER NOT NULL,
    chunk_type VARCHAR(20) NOT NULL,
    page_number INTEGER,
    pdf_page_number INTEGER,
    section_title VARCHAR(200),
    clause_number VARCHAR(50),
    content TEXT NOT NULL,
    content_hash VARCHAR(64),
    token_count INTEGER,
    metadata JSONB,
    embedding VECTOR(1536),
    confidence_score FLOAT DEFAULT 1.0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    CONSTRAINT unique_chunk_per_doc UNIQUE(document_id, chunk_index)
);

-- HNSW ì¸ë±ìŠ¤
CREATE INDEX idx_chunks_embedding ON document_chunks 
USING hnsw (embedding vector_cosine_ops) 
WITH (m = 32, ef_construction = 200);

-- ì¼ë°˜ ì¸ë±ìŠ¤
CREATE INDEX idx_chunks_document_id ON document_chunks(document_id);
CREATE INDEX idx_chunks_page ON document_chunks(page_number);
CREATE INDEX idx_chunks_clause ON document_chunks(clause_number);

-- ê²€ìƒ‰ ë¡œê·¸
CREATE TABLE search_logs (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    query TEXT NOT NULL,
    query_intent VARCHAR(50),
    search_type VARCHAR(20),
    results_count INTEGER,
    top_similarity_score FLOAT,
    response_time_ms INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ì±„íŒ… ì„¸ì…˜
CREATE TABLE chat_sessions (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    session_name VARCHAR(200),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ì±„íŒ… ë©”ì‹œì§€
CREATE TABLE chat_messages (
    id SERIAL PRIMARY KEY,
    session_id INTEGER NOT NULL REFERENCES chat_sessions(id) ON DELETE CASCADE,
    role VARCHAR(20) NOT NULL,
    content TEXT NOT NULL,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### 8.2 ì¸ë±ì‹± ì „ëµ

**HNSW ì¸ë±ìŠ¤**:
- **m=32**: ê° ë…¸ë“œë‹¹ 32ê°œ ì—°ê²° (ì •í™•ë„ì™€ ì„±ëŠ¥ì˜ ê· í˜•)
- **ef_construction=200**: ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œ 200ê°œ í›„ë³´ íƒìƒ‰
- **vector_cosine_ops**: Cosine Similarity ì—°ì‚°ì

**ì„±ëŠ¥ íŠ¹ì„±**:
- ê²€ìƒ‰ ì†ë„: O(log N)
- ì •í™•ë„: ~95% (ANN)
- ë©”ëª¨ë¦¬ ì‚¬ìš©: ~4GB (100ë§Œ ë²¡í„° ê¸°ì¤€)

**ì¼ë°˜ ì¸ë±ìŠ¤**:
```sql
CREATE INDEX idx_chunks_document_id ON document_chunks(document_id);
CREATE INDEX idx_chunks_page ON document_chunks(page_number);
CREATE INDEX idx_chunks_clause ON document_chunks(clause_number);
CREATE INDEX idx_chunks_hash ON document_chunks(content_hash);
```

### 8.3 ì—°ê²° ê´€ë¦¬

**ë¹„ë™ê¸° ì—°ê²° í’€**:
```python
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

# Engine ìƒì„±
engine = create_async_engine(
    "postgresql+asyncpg://user:password@localhost/ispl_db",
    echo=False,
    pool_size=10,
    max_overflow=20
)

# Session Factory
async_session_maker = sessionmaker(
    engine, 
    class_=AsyncSession, 
    expire_on_commit=False
)

# Dependency Injection
async def get_session():
    async with async_session_maker() as session:
        try:
            yield session
        finally:
            await session.close()
```

**ì—°ê²° í’€ ì„¤ì •**:
- `pool_size=10`: ê¸°ë³¸ ì—°ê²° 10ê°œ
- `max_overflow=20`: ìµœëŒ€ 30ê°œê¹Œì§€ í™•ì¥
- `pool_recycle=3600`: 1ì‹œê°„ë§ˆë‹¤ ì—°ê²° ì¬ìƒì„±

---

## 9. Frontend êµ¬í˜„

### 9.1 ê¸°ìˆ  ìŠ¤íƒ

- **Framework**: Next.js 15 (App Router)
- **UI Library**: React 18
- **Styling**: Tailwind CSS 3.4
- **Markdown**: react-markdown + remark-gfm
- **TypeScript**: 5.6

### 9.2 ì£¼ìš” ì»´í¬ë„ŒíŠ¸

#### 9.2.1 AppLayout

**ì—­í• **: ì „ì²´ ë ˆì´ì•„ì›ƒ (Sidebar + Main Content)

```typescript
export default function AppLayout({ children }: { children: React.ReactNode }) {
  const [isSidebarOpen, setIsSidebarOpen] = useState(true);
  
  return (
    <div className="flex h-screen">
      {/* Sidebar */}
      <Sidebar 
        isOpen={isSidebarOpen} 
        onToggle={() => setIsSidebarOpen(!isSidebarOpen)} 
      />
      
      {/* Main Content */}
      <main className="flex-1 overflow-auto">
        {children}
      </main>
    </div>
  );
}
```

#### 9.2.2 ChatMessage

**ì—­í• **: ë©”ì‹œì§€ ë Œë”ë§ (ì‚¬ìš©ì/AI)

```typescript
export function ChatMessage({ message }: { message: Message }) {
  const isUser = message.role === "user";
  
  return (
    <div className={`flex ${isUser ? "justify-end" : "justify-start"} mb-4`}>
      <div className={`max-w-3xl px-4 py-3 rounded-lg ${
        isUser ? "bg-blue-600 text-white" : "bg-gray-100"
      }`}>
        {isUser ? (
          <p>{message.content}</p>
        ) : (
          <ReactMarkdown remarkPlugins={[remarkGfm]}>
            {message.content}
          </ReactMarkdown>
        )}
      </div>
    </div>
  );
}
```

#### 9.2.3 ChatInput

**ì—­í• **: ì§ˆì˜ ì…ë ¥ ë° ì „ì†¡

```typescript
export function ChatInput({ onSend }: { onSend: (query: string) => void }) {
  const [input, setInput] = useState("");
  
  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault();
    if (input.trim()) {
      onSend(input);
      setInput("");
    }
  };
  
  return (
    <form onSubmit={handleSubmit} className="border-t p-4">
      <div className="flex gap-2">
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="ë³´í—˜ ì•½ê´€ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."
          className="flex-1 px-4 py-2 border rounded-lg"
        />
        <button type="submit" className="px-6 py-2 bg-blue-600 text-white rounded-lg">
          ì „ì†¡
        </button>
      </div>
    </form>
  );
}
```

#### 9.2.4 DocumentUpload

**ì—­í• **: PDF ì—…ë¡œë“œ

```typescript
export function DocumentUpload() {
  const [file, setFile] = useState<File | null>(null);
  const [uploading, setUploading] = useState(false);
  
  const handleUpload = async () => {
    if (!file) return;
    
    setUploading(true);
    
    const formData = new FormData();
    formData.append("file", file);
    
    try {
      const response = await fetch("http://localhost:8000/api/documents/upload", {
        method: "POST",
        body: formData
      });
      
      if (response.ok) {
        alert("ì—…ë¡œë“œ ì„±ê³µ!");
        setFile(null);
      }
    } catch (error) {
      alert("ì—…ë¡œë“œ ì‹¤íŒ¨");
    } finally {
      setUploading(false);
    }
  };
  
  return (
    <div className="p-4 border rounded-lg">
      <input
        type="file"
        accept=".pdf"
        onChange={(e) => setFile(e.target.files?.[0] || null)}
      />
      <button onClick={handleUpload} disabled={!file || uploading}>
        {uploading ? "ì—…ë¡œë“œ ì¤‘..." : "ì—…ë¡œë“œ"}
      </button>
    </div>
  );
}
```

#### 9.2.5 ReferencePanel

**ì—­í• **: ì°¸ì¡° ë¬¸ì„œ í‘œì‹œ (í† ê¸€ ê°€ëŠ¥)

```typescript
export function ReferencePanel({ references }: { references: Reference[] }) {
  return (
    <div className="w-80 border-l p-4 overflow-auto">
      <h3 className="font-bold mb-4">ğŸ“š ì°¸ì¡° ë¬¸ì„œ</h3>
      
      {references.map((ref, idx) => (
        <div key={idx} className="mb-4 p-3 bg-gray-50 rounded">
          <div className="text-sm font-medium">[ì°¸ì¡° {idx + 1}]</div>
          <div className="text-xs text-gray-600 mt-1">
            {ref.filename} (í˜ì´ì§€ {ref.page_number})
          </div>
          <div className="text-sm mt-2">{ref.content}</div>
          <div className="text-xs text-blue-600 mt-2">
            ìœ ì‚¬ë„: {(ref.similarity * 100).toFixed(1)}%
          </div>
        </div>
      ))}
    </div>
  );
}
```

### 9.3 API í†µì‹ 

**API í´ë¼ì´ì–¸íŠ¸** (`lib/api.ts`):
```typescript
const API_BASE_URL = "http://localhost:8000/api";

export async function sendChatMessage(query: string): Promise<ChatResponse> {
  const response = await fetch(`${API_BASE_URL}/chat`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ query })
  });
  
  return response.json();
}

export async function uploadDocument(file: File): Promise<UploadResponse> {
  const formData = new FormData();
  formData.append("file", file);
  
  const response = await fetch(`${API_BASE_URL}/documents/upload`, {
    method: "POST",
    body: formData
  });
  
  return response.json();
}

export async function listDocuments(): Promise<Document[]> {
  const response = await fetch(`${API_BASE_URL}/documents`);
  return response.json();
}
```

### 9.4 í˜ì´ì§€ êµ¬ì¡°

```
app/
â”œâ”€â”€ layout.tsx                 # ë£¨íŠ¸ ë ˆì´ì•„ì›ƒ
â”œâ”€â”€ page.tsx                   # í™ˆ (ì±„íŒ… í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸)
â”œâ”€â”€ chat/
â”‚   â””â”€â”€ page.tsx              # ì±„íŒ… UI (GPT ìŠ¤íƒ€ì¼)
â”œâ”€â”€ documents/
â”‚   â””â”€â”€ page.tsx              # ë¬¸ì„œ ê´€ë¦¬
â””â”€â”€ history/
    â””â”€â”€ page.tsx              # ëŒ€í™” ì´ë ¥
```

**ì±„íŒ… í˜ì´ì§€** (`app/chat/page.tsx`):
```typescript
'use client';

export default function ChatPage() {
  const [messages, setMessages] = useState<Message[]>([]);
  const [references, setReferences] = useState<Reference[]>([]);
  
  const handleSend = async (query: string) => {
    // ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    setMessages(prev => [...prev, { role: "user", content: query }]);
    
    // API í˜¸ì¶œ
    const response = await sendChatMessage(query);
    
    // AI ë©”ì‹œì§€ ì¶”ê°€
    setMessages(prev => [...prev, { 
      role: "assistant", 
      content: response.answer 
    }]);
    
    // ì°¸ì¡° ë¬¸ì„œ ì—…ë°ì´íŠ¸
    setReferences(response.references);
  };
  
  return (
    <div className="flex h-screen">
      {/* ì±„íŒ… ì˜ì—­ */}
      <div className="flex-1 flex flex-col">
        <div className="flex-1 overflow-auto p-4">
          {messages.map((msg, idx) => (
            <ChatMessage key={idx} message={msg} />
          ))}
        </div>
        <ChatInput onSend={handleSend} />
      </div>
      
      {/* ì°¸ì¡° íŒ¨ë„ */}
      <ReferencePanel references={references} />
    </div>
  );
}
```

---

## 10. ì„±ëŠ¥ ìµœì í™”

### 10.1 Embedding ìºì‹±

**ë¬¸ì œ**: ë™ì¼ í…ìŠ¤íŠ¸ ì¤‘ë³µ ì„ë² ë”© ìƒì„±

**í•´ê²°**:
```python
class EmbeddingCache:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.ttl = 86400 * 7  # 7ì¼
    
    async def get_or_create(self, text: str) -> List[float]:
        """ìºì‹œì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒì„±"""
        # ìºì‹œ í‚¤ ìƒì„± (í…ìŠ¤íŠ¸ í•´ì‹œ)
        cache_key = f"emb:{hashlib.sha256(text.encode()).hexdigest()}"
        
        # ìºì‹œ ì¡°íšŒ
        cached = await self.redis.get(cache_key)
        if cached:
            return json.loads(cached)
        
        # ì„ë² ë”© ìƒì„±
        embedding = await self.embedding_service.generate_embedding(text)
        
        # ìºì‹œ ì €ì¥
        await self.redis.setex(cache_key, self.ttl, json.dumps(embedding))
        
        return embedding
```

**íš¨ê³¼**: ì¤‘ë³µ ì„ë² ë”© ìƒì„± 90% ê°ì†Œ

### 10.2 ë°°ì¹˜ ì²˜ë¦¬

**PDF ì²˜ë¦¬**:
```python
async def process_multiple_pdfs(pdf_paths: List[str]):
    """ì—¬ëŸ¬ PDF ë³‘ë ¬ ì²˜ë¦¬"""
    tasks = [
        process_pdf(path, method="pymupdf")
        for path in pdf_paths
    ]
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    return results
```

**ì„ë² ë”© ìƒì„±**:
```python
async def generate_embeddings_batch(texts: List[str], batch_size: int = 100):
    """ë°°ì¹˜ ì„ë² ë”© ìƒì„±"""
    embeddings = []
    
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        batch_embeddings = await embedding_service.generate_embeddings(batch)
        embeddings.extend(batch_embeddings)
    
    return embeddings
```

### 10.3 ì—°ê²° í’€ë§

**PostgreSQL**:
```python
engine = create_async_engine(
    DATABASE_URL,
    pool_size=10,
    max_overflow=20,
    pool_pre_ping=True,
    pool_recycle=3600
)
```

**íš¨ê³¼**: ì—°ê²° ìƒì„± ì‹œê°„ 80% ê°ì†Œ

### 10.4 ì¸ë±ìŠ¤ ìµœì í™”

**HNSW íŒŒë¼ë¯¸í„° íŠœë‹**:
```sql
-- ì •í™•ë„ ìš°ì„ 
CREATE INDEX idx_high_accuracy ON document_chunks 
USING hnsw (embedding vector_cosine_ops) 
WITH (m = 64, ef_construction = 400);

-- ì†ë„ ìš°ì„ 
CREATE INDEX idx_high_speed ON document_chunks 
USING hnsw (embedding vector_cosine_ops) 
WITH (m = 16, ef_construction = 100);

-- ê· í˜• (í˜„ì¬ ì‚¬ìš©)
CREATE INDEX idx_balanced ON document_chunks 
USING hnsw (embedding vector_cosine_ops) 
WITH (m = 32, ef_construction = 200);
```

### 10.5 í† í° ìµœì í™”

**ì»¨í…ìŠ¤íŠ¸ ì••ì¶•**:
```python
def optimize_context(chunks: List[dict], max_tokens: int = 20000) -> List[dict]:
    """ë¶ˆí•„ìš”í•œ ë‚´ìš© ì œê±° ë° ì••ì¶•"""
    optimized = []
    total_tokens = 0
    
    for chunk in chunks:
        # ì¤‘ë³µ ì œê±°
        if chunk["content"] in [c["content"] for c in optimized]:
            continue
        
        # í† í° ì œí•œ
        if total_tokens + chunk["token_count"] > max_tokens:
            break
        
        optimized.append(chunk)
        total_tokens += chunk["token_count"]
    
    return optimized
```

---

## 11. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

### 11.1 í…ŒìŠ¤íŠ¸ êµ¬ì¡°

```
backend/test/
â”œâ”€â”€ test_pdf_processing.py              # PDF ì „ì²˜ë¦¬
â”œâ”€â”€ test_chunking.py                    # ì²­í‚¹
â”œâ”€â”€ test_vector_search.py               # ë²¡í„° ê²€ìƒ‰
â”œâ”€â”€ test_hybrid_search_integration.py   # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
â”œâ”€â”€ test_query_preprocessor_complete.py # ì¿¼ë¦¬ ì „ì²˜ë¦¬
â”œâ”€â”€ test_answer_validator_integration.py # ë‹µë³€ ê²€ì¦
â”œâ”€â”€ test_langgraph_agents.py            # LangGraph ì›Œí¬í”Œë¡œìš°
â””â”€â”€ test_api_integration.py             # API í†µí•© í…ŒìŠ¤íŠ¸
```

### 11.2 ì£¼ìš” í…ŒìŠ¤íŠ¸

**PDF ì²˜ë¦¬ í…ŒìŠ¤íŠ¸**:
```python
@pytest.mark.asyncio
async def test_pdf_processing():
    processor = PDFProcessor()
    
    result = await processor.process_pdf(
        pdf_path="test_insurance.pdf",
        document_id=1,
        method="pymupdf"
    )
    
    assert result["success"] == True
    assert len(result["chunks"]) > 0
    assert all(c["embedding"] is not None for c in result["chunks"])
```

**í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸**:
```python
@pytest.mark.asyncio
async def test_hybrid_search():
    service = HybridSearchService()
    
    results = await service.search(
        session=db_session,
        query="ê³¨ì ˆ ì‹œ ë³´í—˜ê¸ˆì€?",
        limit=10
    )
    
    assert len(results) > 0
    assert all(r["similarity"] >= 0.7 for r in results)
```

**ë‹µë³€ ê²€ì¦ í…ŒìŠ¤íŠ¸**:
```python
@pytest.mark.asyncio
async def test_answer_validation():
    validator = AnswerValidator()
    
    validation = await validator.validate(
        answer="...",
        query="...",
        context_chunks=[...]
    )
    
    assert validation.overall_score >= 0.7
    assert validation.passed == True
```

### 11.3 ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

| ì‘ì—… | í‰ê·  ì‹œê°„ | ëª©í‘œ |
|-----|---------|-----|
| PDF ì „ì²˜ë¦¬ (10í˜ì´ì§€) | 2.5ì´ˆ | <5ì´ˆ |
| ë²¡í„° ê²€ìƒ‰ (10ê°œ) | 0.15ì´ˆ | <0.5ì´ˆ |
| í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ | 0.3ì´ˆ | <1ì´ˆ |
| ë‹µë³€ ìƒì„± | 3.2ì´ˆ | <5ì´ˆ |
| ì „ì²´ ì‘ë‹µ ì‹œê°„ | 4.8ì´ˆ | <10ì´ˆ |

---

## 12. ìš´ì˜ ë° ëª¨ë‹ˆí„°ë§

### 12.1 ë¡œê¹…

**ë¡œê¹… ì„¤ì •**:
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/ispl.log'),
        logging.StreamHandler()
    ]
)
```

**ì£¼ìš” ë¡œê·¸**:
- PDF ì²˜ë¦¬ ì‹œì‘/ì™„ë£Œ
- ê²€ìƒ‰ ì¿¼ë¦¬ ë° ê²°ê³¼ ìˆ˜
- ë‹µë³€ ìƒì„± ë° ê²€ì¦ ì ìˆ˜
- API ìš”ì²­/ì‘ë‹µ ì‹œê°„
- ì—ëŸ¬ ë°œìƒ ë° ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤

### 12.2 ì—ëŸ¬ ì²˜ë¦¬

**ê¸€ë¡œë²Œ ì˜ˆì™¸ í•¸ë“¤ëŸ¬**:
```python
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal Server Error",
            "message": str(exc)
        }
    )
```

### 12.3 í™˜ê²½ ë³€ìˆ˜

`.env`:
```bash
# Database
DATABASE_URL=postgresql+asyncpg://user:password@localhost/ispl_db

# OpenAI
OPENAI_API_KEY=sk-...

# Redis (Optional)
REDIS_UR